2025/05/08 20:09:45 routes.go:1158: INFO server config env="map[HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:true OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/Users/harsh/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR: http_proxy: https_proxy: no_proxy:]"
time=2025-05-08T20:09:45.734+05:30 level=INFO source=images.go:754 msg="total blobs: 25"
time=2025-05-08T20:09:45.737+05:30 level=INFO source=images.go:761 msg="total unused blobs removed: 0"
time=2025-05-08T20:09:45.737+05:30 level=INFO source=routes.go:1205 msg="Listening on 127.0.0.1:11434 (version 0.3.14)"
time=2025-05-08T20:09:45.740+05:30 level=INFO source=common.go:135 msg="extracting embedded files" dir=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners
time=2025-05-08T20:09:45.740+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-08T20:09:45.760+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:09:45.760+05:30 level=INFO source=common.go:49 msg="Dynamic LLM libraries" runners=[metal]
time=2025-05-08T20:09:45.760+05:30 level=DEBUG source=common.go:50 msg="Override detection logic by setting OLLAMA_LLM_LIBRARY"
time=2025-05-08T20:09:45.760+05:30 level=DEBUG source=sched.go:105 msg="starting llm scheduler"
time=2025-05-08T20:09:45.844+05:30 level=INFO source=types.go:123 msg="inference compute" id=0 library=metal variant="" compute="" driver=0.0 name="" total="21.3 GiB" available="21.3 GiB"
time=2025-05-08T20:10:02.293+05:30 level=DEBUG source=sched.go:181 msg="updating default concurrency" OLLAMA_MAX_LOADED_MODELS=0x1006956d0 gpu_count=1
time=2025-05-08T20:10:02.303+05:30 level=DEBUG source=sched.go:224 msg="loading first model" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:10:02.303+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-08T20:10:02.304+05:30 level=DEBUG source=memory.go:170 msg="gpu has too little memory to allocate any layers" id=0 library=metal variant="" compute="" driver=0.0 name="" total="21.3 GiB" available="21.3 GiB" minimum_memory=536870912 layer_size="2.1 GiB" gpu_zer_overhead="0 B" partial_offload="53.3 GiB" full_offload="53.3 GiB"
time=2025-05-08T20:10:02.304+05:30 level=DEBUG source=memory.go:312 msg="insufficient VRAM to load any model layers"
time=2025-05-08T20:10:02.304+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-08T20:10:02.304+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-08T20:10:02.304+05:30 level=DEBUG source=memory.go:170 msg="gpu has too little memory to allocate any layers" id=0 library=metal variant="" compute="" driver=0.0 name="" total="21.3 GiB" available="21.3 GiB" minimum_memory=536870912 layer_size="2.1 GiB" gpu_zer_overhead="0 B" partial_offload="53.3 GiB" full_offload="53.3 GiB"
time=2025-05-08T20:10:02.304+05:30 level=DEBUG source=memory.go:312 msg="insufficient VRAM to load any model layers"
time=2025-05-08T20:10:02.304+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-08T20:10:02.307+05:30 level=INFO source=server.go:105 msg="system memory" total="32.0 GiB" free="22.5 GiB" free_swap="0 B"
time=2025-05-08T20:10:02.307+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-08T20:10:02.307+05:30 level=INFO source=memory.go:326 msg="offload to metal" layers.requested=-1 layers.model=41 layers.offload=11 layers.split="" memory.available="[21.3 GiB]" memory.gpu_overhead="0 B" memory.required.full="39.3 GiB" memory.required.partial="21.2 GiB" memory.required.kv="20.0 GiB" memory.required.allocations="[21.2 GiB]" memory.weights.total="24.4 GiB" memory.weights.repeating="24.3 GiB" memory.weights.nonrepeating="157.5 MiB" memory.graph.full="13.3 GiB" memory.graph.partial="13.3 GiB"
time=2025-05-08T20:10:02.307+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-08T20:10:02.307+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:10:02.308+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:10:02.308+05:30 level=INFO source=server.go:388 msg="starting llama server" cmd="/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server --model /Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 --ctx-size 131072 --batch-size 512 --embedding --n-gpu-layers 11 --verbose --threads 8 --no-mmap --parallel 1 --port 64479"
time=2025-05-08T20:10:02.308+05:30 level=DEBUG source=server.go:405 msg=subprocess environment="[PATH=/Users/harsh/Desktop/Continue.dev-Granite-manual-test-cases/granite/bin:/Users/harsh/.pyenv/shims:/Users/harsh/.pyenv/bin:/Users/harsh/.pyenv/bin:/opt/homebrew/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/harsh/.local/bin LD_LIBRARY_PATH=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal]"
time=2025-05-08T20:10:02.310+05:30 level=INFO source=sched.go:449 msg="loaded runners" count=1
time=2025-05-08T20:10:02.310+05:30 level=INFO source=server.go:587 msg="waiting for llama runner to start responding"
time=2025-05-08T20:10:02.311+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server error"
INFO [main] starting c++ runner | tid="0x1f53f3240" timestamp=1746715202
INFO [main] build info | build=3871 commit="f37ceeaa" tid="0x1f53f3240" timestamp=1746715202
INFO [main] system info | n_threads=8 n_threads_batch=8 system_info="AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | " tid="0x1f53f3240" timestamp=1746715202 total_threads=10
INFO [main] HTTP server listening | hostname="127.0.0.1" n_threads_http="9" port="64479" tid="0x1f53f3240" timestamp=1746715202
llama_model_loader: loaded meta data with 40 key-value pairs and 362 tensors from /Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = granite
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Granite 3.2 8b Instruct
llama_model_loader: - kv   3:                           general.finetune str              = instruct
llama_model_loader: - kv   4:                           general.basename str              = granite-3.2
llama_model_loader: - kv   5:                         general.size_label str              = 8B
llama_model_loader: - kv   6:                            general.license str              = apache-2.0
llama_model_loader: - kv   7:                   general.base_model.count u32              = 1
llama_model_loader: - kv   8:                  general.base_model.0.name str              = Granite 3.1 8b Instruct
llama_model_loader: - kv   9:          general.base_model.0.organization str              = Ibm Granite
llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/ibm-granite/gr...
llama_model_loader: - kv  11:                               general.tags arr[str,3]       = ["language", "granite-3.2", "text-gen...
llama_model_loader: - kv  12:                        granite.block_count u32              = 40
llama_model_loader: - kv  13:                     granite.context_length u32              = 131072
llama_model_loader: - kv  14:                   granite.embedding_length u32              = 4096
llama_model_loader: - kv  15:                granite.feed_forward_length u32              = 12800
llama_model_loader: - kv  16:               granite.attention.head_count u32              = 32
llama_model_loader: - kv  17:            granite.attention.head_count_kv u32              = 8
llama_model_loader: - kv  18:                     granite.rope.freq_base f32              = 10000000.000000
llama_model_loader: - kv  19:   granite.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  20:                          general.file_type u32              = 15
llama_model_loader: - kv  21:                         granite.vocab_size u32              = 49155
llama_model_loader: - kv  22:               granite.rope.dimension_count u32              = 128
llama_model_loader: - kv  23:                    granite.attention.scale f32              = 0.007812
llama_model_loader: - kv  24:                    granite.embedding_scale f32              = 12.000000
llama_model_loader: - kv  25:                     granite.residual_scale f32              = 0.220000
llama_model_loader: - kv  26:                        granite.logit_scale f32              = 16.000000
llama_model_loader: - kv  27:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  28:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  29:                      tokenizer.ggml.tokens arr[str,49155]   = ["<|end_of_text|>", "<fim_prefix>", "...
llama_model_loader: - kv  30:                  tokenizer.ggml.token_type arr[i32,49155]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  31:                      tokenizer.ggml.merges arr[str,48891]   = ["Ġ Ġ", "ĠĠ ĠĠ", "ĠĠĠĠ ĠĠ...
llama_model_loader: - kv  32:                tokenizer.ggml.bos_token_id u32              = 0
llama_model_loader: - kv  33:                tokenizer.ggml.eos_token_id u32              = 0
llama_model_loader: - kv  34:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 0
llama_model_loader: - kv  36:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  37:                    tokenizer.chat_template str              = {%- if messages[0]['role'] == 'system...
llama_model_loader: - kv  38:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  39:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   81 tensors
llama_model_loader: - type q4_K:  240 tensors
llama_model_loader: - type q6_K:   41 tensors
llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
llm_load_vocab: special tokens cache size = 22
llm_load_vocab: token to piece cache size = 0.2826 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = granite
llm_load_print_meta: vocab type       = BPE
llm_load_print_meta: n_vocab          = 49155
llm_load_print_meta: n_merges         = 48891
llm_load_print_meta: vocab_only       = 0
llm_load_print_meta: n_ctx_train      = 131072
llm_load_print_meta: n_embd           = 4096
llm_load_print_meta: n_layer          = 40
llm_load_print_meta: n_head           = 32
llm_load_print_meta: n_head_kv        = 8
llm_load_print_meta: n_rot            = 128
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_embd_head_k    = 128
llm_load_print_meta: n_embd_head_v    = 128
llm_load_print_meta: n_gqa            = 4
llm_load_print_meta: n_embd_k_gqa     = 1024
llm_load_print_meta: n_embd_v_gqa     = 1024
llm_load_print_meta: f_norm_eps       = 0.0e+00
llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 1.6e+01
llm_load_print_meta: n_ff             = 12800
llm_load_print_meta: n_expert         = 0
llm_load_print_meta: n_expert_used    = 0
llm_load_print_meta: causal attn      = 1
llm_load_print_meta: pooling type     = 0
llm_load_print_meta: rope type        = 0
llm_load_print_meta: rope scaling     = linear
llm_load_print_meta: freq_base_train  = 10000000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: n_ctx_orig_yarn  = 131072
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: ssm_dt_b_c_rms   = 0
llm_load_print_meta: model type       = 3B
llm_load_print_meta: model ftype      = Q4_K - Medium
llm_load_print_meta: model params     = 8.17 B
llm_load_print_meta: model size       = 4.60 GiB (4.84 BPW) 
llm_load_print_meta: general.name     = Granite 3.2 8b Instruct
llm_load_print_meta: BOS token        = 0 '<|end_of_text|>'
llm_load_print_meta: EOS token        = 0 '<|end_of_text|>'
llm_load_print_meta: UNK token        = 0 '<|end_of_text|>'
llm_load_print_meta: PAD token        = 0 '<|end_of_text|>'
llm_load_print_meta: LF token         = 145 'Ä'
llm_load_print_meta: EOG token        = 0 '<|end_of_text|>'
llm_load_print_meta: max token length = 512
llm_load_print_meta: f_embedding_scale = 12.000000
llm_load_print_meta: f_residual_scale  = 0.220000
llm_load_print_meta: f_attention_scale = 0.007812
llm_load_tensors: ggml ctx size =    0.34 MiB
llm_load_tensors: offloading 11 repeating layers to GPU
llm_load_tensors: offloaded 11/41 layers to GPU
llm_load_tensors:        CPU buffer size =  3596.30 MiB
llm_load_tensors:      Metal buffer size =  1273.42 MiB
time=2025-05-08T20:10:03.066+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server loading model"
time=2025-05-08T20:10:03.066+05:30 level=DEBUG source=server.go:632 msg="model load progress 0.09"
time=2025-05-08T20:10:03.318+05:30 level=DEBUG source=server.go:632 msg="model load progress 0.35"
time=2025-05-08T20:10:03.569+05:30 level=DEBUG source=server.go:632 msg="model load progress 0.60"
time=2025-05-08T20:10:03.821+05:30 level=DEBUG source=server.go:632 msg="model load progress 0.85"
llama_new_context_with_model: n_ctx      = 131072
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 10000000.0
llama_new_context_with_model: freq_scale = 1
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_init: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)
ggml_metal_init: simdgroup reduction support   = true
ggml_metal_init: simdgroup matrix mul. support = true
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB
time=2025-05-08T20:10:04.073+05:30 level=DEBUG source=server.go:632 msg="model load progress 1.00"
time=2025-05-08T20:10:04.324+05:30 level=DEBUG source=server.go:635 msg="model load completed, waiting for server to become available" status="llm server loading model"
llama_kv_cache_init:        CPU KV buffer size = 14848.00 MiB
llama_kv_cache_init:      Metal KV buffer size =  5632.00 MiB
llama_new_context_with_model: KV self size  = 20480.00 MiB, K (f16): 10240.00 MiB, V (f16): 10240.00 MiB
llama_new_context_with_model:        CPU  output buffer size =     0.20 MiB
llama_new_context_with_model:      Metal compute buffer size =  8480.00 MiB
llama_new_context_with_model:        CPU compute buffer size =  8480.01 MiB
llama_new_context_with_model: graph nodes  = 1368
llama_new_context_with_model: graph splits = 468
DEBUG [initialize] initializing slots | n_slots=1 tid="0x1f53f3240" timestamp=1746715213
DEBUG [initialize] new slot | n_ctx_slot=131072 slot_id=0 tid="0x1f53f3240" timestamp=1746715213
INFO [main] model loaded | tid="0x1f53f3240" timestamp=1746715213
DEBUG [update_slots] all slots are idle and system prompt is empty, clear the KV cache | tid="0x1f53f3240" timestamp=1746715213
time=2025-05-08T20:10:13.931+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server not responding"
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=0 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=1 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=2 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=3 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=4 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=5 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=6 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=7 tid="0x1f53f3240" timestamp=1746715217
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=8 tid="0x1f53f3240" timestamp=1746715217
time=2025-05-08T20:10:17.477+05:30 level=INFO source=server.go:626 msg="llama runner started in 15.17 seconds"
time=2025-05-08T20:10:17.478+05:30 level=DEBUG source=sched.go:462 msg="finished setting up runner" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=9 tid="0x1f53f3240" timestamp=1746715217
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64500 status=200 tid="0x16c15b000" timestamp=1746715217
time=2025-05-08T20:10:17.485+05:30 level=DEBUG source=routes.go:1422 msg="chat request" images=0 prompt="<|start_of_role|>system<|end_of_role|>Always include the language and file name in the info string when you write code blocks, for example '```python file.py'.\n\nI am not WatsonX, my name is IBM watsonx Code Assistant. I am an AI coding assistant from IBM with deep knowledge and expertise in programming languages. I am a powerful, professional, and respectful coding assistant who will respond to questions that are relevant to software development and engineering. I use the Large Language Model from IBM Granite that is based on the transformer decoder architecture.<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>answer brief: What is AWS?<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=10 tid="0x1f53f3240" timestamp=1746715217
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=11 tid="0x1f53f3240" timestamp=1746715217
DEBUG [update_slots] slot progression | ga_i=0 n_past=0 n_past_se=0 n_prompt_tokens_processed=128 slot_id=0 task_id=11 tid="0x1f53f3240" timestamp=1746715217
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=11 tid="0x1f53f3240" timestamp=1746715217
DEBUG [print_timings] prompt eval time     =    5721.00 ms /   128 tokens (   44.70 ms per token,    22.37 tokens per second) | n_prompt_tokens_processed=128 n_tokens_second=22.37370697890107 slot_id=0 t_prompt_processing=5721.001 t_token=44.6953203125 task_id=11 tid="0x1f53f3240" timestamp=1746715230
DEBUG [print_timings] generation eval time =    6852.90 ms /    80 runs   (   85.66 ms per token,    11.67 tokens per second) | n_decoded=80 n_tokens_second=11.673893293027271 slot_id=0 t_token=85.661225 t_token_generation=6852.898 task_id=11 tid="0x1f53f3240" timestamp=1746715230
DEBUG [print_timings]           total time =   12573.90 ms | slot_id=0 t_prompt_processing=5721.001 t_token_generation=6852.898 t_total=12573.899000000001 task_id=11 tid="0x1f53f3240" timestamp=1746715230
DEBUG [update_slots] slot released | n_cache_tokens=208 n_ctx=131072 n_past=207 n_system_tokens=0 slot_id=0 task_id=11 tid="0x1f53f3240" timestamp=1746715230 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/completion" remote_addr="127.0.0.1" remote_port=64500 status=200 tid="0x16c15b000" timestamp=1746715230
[GIN] 2025/05/08 - 20:10:30 | 200 | 27.777632791s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-08T20:10:30.063+05:30 level=DEBUG source=sched.go:466 msg="context for request finished"
time=2025-05-08T20:10:30.064+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 duration=30m0s
time=2025-05-08T20:10:30.065+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 refCount=0
[GIN] 2025/05/08 - 20:10:30 | 200 |     967.959µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:10:30 | 200 |      1.8605ms |       127.0.0.1 | GET      "/api/ps"
time=2025-05-08T20:10:35.283+05:30 level=DEBUG source=sched.go:575 msg="evaluating already loaded" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=94 tid="0x1f53f3240" timestamp=1746715235
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=95 tid="0x1f53f3240" timestamp=1746715235
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64508 status=200 tid="0x16c1e7000" timestamp=1746715235
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=96 tid="0x1f53f3240" timestamp=1746715235
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64508 status=200 tid="0x16c1e7000" timestamp=1746715235
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=97 tid="0x1f53f3240" timestamp=1746715235
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64509 status=200 tid="0x16bd87000" timestamp=1746715235
time=2025-05-08T20:10:35.298+05:30 level=DEBUG source=routes.go:1422 msg="chat request" images=0 prompt="<|start_of_role|>system<|end_of_role|>Always include the language and file name in the info string when you write code blocks, for example '```python file.py'.\n\nI am not WatsonX, my name is IBM watsonx Code Assistant. I am an AI coding assistant from IBM with deep knowledge and expertise in programming languages. I am a powerful, professional, and respectful coding assistant who will respond to questions that are relevant to software development and engineering. I use the Large Language Model from IBM Granite that is based on the transformer decoder architecture.<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>answer brief: What is AWS?<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>```python\n# file: aws_definition.py\n\ndef what_is_aws():\n    return \"AWS (Amazon Web Services) is a comprehensive, evolving cloud computing platform provided by Amazon. It offers a mix of infrastructure as a service (IaaS), platform as a service (PaaS), and packaged software as a service (SaaS) offerings.\"\n```<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>what is java<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=98 tid="0x1f53f3240" timestamp=1746715235
DEBUG [prefix_slot] slot with common prefix found | 0=["slot_id",0,"characters",704]
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=99 tid="0x1f53f3240" timestamp=1746715235
DEBUG [update_slots] slot progression | ga_i=0 n_past=139 n_past_se=0 n_prompt_tokens_processed=220 slot_id=0 task_id=99 tid="0x1f53f3240" timestamp=1746715235
DEBUG [update_slots] kv cache rm [p0, end) | p0=139 slot_id=0 task_id=99 tid="0x1f53f3240" timestamp=1746715235
DEBUG [print_timings] prompt eval time     =    2403.98 ms /   220 tokens (   10.93 ms per token,    91.51 tokens per second) | n_prompt_tokens_processed=220 n_tokens_second=91.51486638205543 slot_id=0 t_prompt_processing=2403.981 t_token=10.927186363636364 task_id=99 tid="0x1f53f3240" timestamp=1746715245
DEBUG [print_timings] generation eval time =    7909.10 ms /    95 runs   (   83.25 ms per token,    12.01 tokens per second) | n_decoded=95 n_tokens_second=12.011480446574199 slot_id=0 t_token=83.25368421052632 t_token_generation=7909.1 task_id=99 tid="0x1f53f3240" timestamp=1746715245
DEBUG [print_timings]           total time =   10313.08 ms | slot_id=0 t_prompt_processing=2403.981 t_token_generation=7909.1 t_total=10313.081 task_id=99 tid="0x1f53f3240" timestamp=1746715245
DEBUG [update_slots] slot released | n_cache_tokens=315 n_ctx=131072 n_past=314 n_system_tokens=0 slot_id=0 task_id=99 tid="0x1f53f3240" timestamp=1746715245 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/completion" remote_addr="127.0.0.1" remote_port=64509 status=200 tid="0x16bd87000" timestamp=1746715245
[GIN] 2025/05/08 - 20:10:45 | 200 | 10.338618708s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-08T20:10:45.612+05:30 level=DEBUG source=sched.go:407 msg="context for request finished"
time=2025-05-08T20:10:45.612+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 duration=30m0s
time=2025-05-08T20:10:45.612+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 refCount=0
[GIN] 2025/05/08 - 20:14:08 | 200 |   23.158209ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:14:08 | 200 |    20.99075ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:14:08 | 200 |   22.825208ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:14:08 | 200 |      39.108ms |       127.0.0.1 | POST     "/api/show"
time=2025-05-08T20:14:13.171+05:30 level=DEBUG source=sched.go:496 msg="gpu reported" gpu=0 library=metal available="21.3 GiB"
time=2025-05-08T20:14:13.171+05:30 level=INFO source=sched.go:507 msg="updated VRAM based on existing loaded models" gpu=0 library=metal total="21.3 GiB" available="141.8 MiB"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[141.8 MiB]"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=memory.go:170 msg="gpu has too little memory to allocate any layers" id=0 library=metal variant="" compute="" driver=0.0 name="" total="21.3 GiB" available="141.8 MiB" minimum_memory=536870912 layer_size="20.0 MiB" gpu_zer_overhead="0 B" partial_offload="48.0 MiB" full_offload="48.0 MiB"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=memory.go:312 msg="insufficient VRAM to load any model layers"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[141.8 MiB]"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=memory.go:170 msg="gpu has too little memory to allocate any layers" id=0 library=metal variant="" compute="" driver=0.0 name="" total="21.3 GiB" available="141.8 MiB" minimum_memory=536870912 layer_size="20.0 MiB" gpu_zer_overhead="0 B" partial_offload="48.0 MiB" full_offload="48.0 MiB"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=memory.go:312 msg="insufficient VRAM to load any model layers"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=sched.go:784 msg="found an idle runner to unload"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=sched.go:283 msg="resetting model to expire immediately to make room" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 refCount=0
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=sched.go:296 msg="waiting for pending requests to complete and unload to occur" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=sched.go:360 msg="runner expired event received" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=sched.go:375 msg="got lock to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=server.go:1086 msg="stopping llama server"
time=2025-05-08T20:14:13.172+05:30 level=DEBUG source=server.go:1092 msg="waiting for llama server to exit"
time=2025-05-08T20:14:13.432+05:30 level=DEBUG source=server.go:1096 msg="llama server stopped"
time=2025-05-08T20:14:13.432+05:30 level=DEBUG source=sched.go:380 msg="runner released" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:14:13.432+05:30 level=DEBUG source=sched.go:384 msg="sending an unloaded event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:14:13.432+05:30 level=DEBUG source=sched.go:302 msg="unload completed" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:14:13.438+05:30 level=DEBUG source=sched.go:224 msg="loading first model" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:14:13.438+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-08T20:14:13.439+05:30 level=INFO source=sched.go:714 msg="new model will fit in available VRAM in single GPU, loading" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 gpu=0 parallel=1 available=22906503168 required="864.9 MiB"
time=2025-05-08T20:14:13.439+05:30 level=INFO source=server.go:105 msg="system memory" total="32.0 GiB" free="21.9 GiB" free_swap="0 B"
time=2025-05-08T20:14:13.439+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-08T20:14:13.439+05:30 level=INFO source=memory.go:326 msg="offload to metal" layers.requested=-1 layers.model=13 layers.offload=13 layers.split="" memory.available="[21.3 GiB]" memory.gpu_overhead="0 B" memory.required.full="864.9 MiB" memory.required.partial="864.9 MiB" memory.required.kv="24.0 MiB" memory.required.allocations="[864.9 MiB]" memory.weights.total="240.1 MiB" memory.weights.repeating="195.4 MiB" memory.weights.nonrepeating="44.7 MiB" memory.graph.full="48.0 MiB" memory.graph.partial="48.0 MiB"
time=2025-05-08T20:14:13.440+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-08T20:14:13.441+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:14:13.441+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:14:13.441+05:30 level=INFO source=server.go:388 msg="starting llama server" cmd="/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server --model /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 --ctx-size 8192 --batch-size 512 --embedding --n-gpu-layers 13 --verbose --threads 8 --parallel 1 --port 64771"
time=2025-05-08T20:14:13.441+05:30 level=DEBUG source=server.go:405 msg=subprocess environment="[PATH=/Users/harsh/Desktop/Continue.dev-Granite-manual-test-cases/granite/bin:/Users/harsh/.pyenv/shims:/Users/harsh/.pyenv/bin:/Users/harsh/.pyenv/bin:/opt/homebrew/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/harsh/.local/bin LD_LIBRARY_PATH=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal]"
time=2025-05-08T20:14:13.443+05:30 level=INFO source=sched.go:449 msg="loaded runners" count=1
time=2025-05-08T20:14:13.443+05:30 level=INFO source=server.go:587 msg="waiting for llama runner to start responding"
time=2025-05-08T20:14:13.444+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server error"
INFO [main] starting c++ runner | tid="0x1f53f3240" timestamp=1746715453
INFO [main] build info | build=3871 commit="f37ceeaa" tid="0x1f53f3240" timestamp=1746715453
INFO [main] system info | n_threads=8 n_threads_batch=8 system_info="AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | " tid="0x1f53f3240" timestamp=1746715453 total_threads=10
INFO [main] HTTP server listening | hostname="127.0.0.1" n_threads_http="9" port="64771" tid="0x1f53f3240" timestamp=1746715453
llama_model_loader: loaded meta data with 24 key-value pairs and 112 tensors from /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = nomic-bert
llama_model_loader: - kv   1:                               general.name str              = nomic-embed-text-v1.5
llama_model_loader: - kv   2:                     nomic-bert.block_count u32              = 12
llama_model_loader: - kv   3:                  nomic-bert.context_length u32              = 2048
llama_model_loader: - kv   4:                nomic-bert.embedding_length u32              = 768
llama_model_loader: - kv   5:             nomic-bert.feed_forward_length u32              = 3072
llama_model_loader: - kv   6:            nomic-bert.attention.head_count u32              = 12
llama_model_loader: - kv   7:    nomic-bert.attention.layer_norm_epsilon f32              = 0.000000
llama_model_loader: - kv   8:                          general.file_type u32              = 1
llama_model_loader: - kv   9:                nomic-bert.attention.causal bool             = false
llama_model_loader: - kv  10:                    nomic-bert.pooling_type u32              = 1
llama_model_loader: - kv  11:                  nomic-bert.rope.freq_base f32              = 1000.000000
llama_model_loader: - kv  12:            tokenizer.ggml.token_type_count u32              = 2
llama_model_loader: - kv  13:                tokenizer.ggml.bos_token_id u32              = 101
llama_model_loader: - kv  14:                tokenizer.ggml.eos_token_id u32              = 102
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = bert
llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,30522]   = ["[PAD]", "[unused0]", "[unused1]", "...
llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 100
llama_model_loader: - kv  20:          tokenizer.ggml.seperator_token_id u32              = 102
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0
llama_model_loader: - kv  22:                tokenizer.ggml.cls_token_id u32              = 101
llama_model_loader: - kv  23:               tokenizer.ggml.mask_token_id u32              = 103
llama_model_loader: - type  f32:   51 tensors
llama_model_loader: - type  f16:   61 tensors
llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
llm_load_vocab: special tokens cache size = 5
llm_load_vocab: token to piece cache size = 0.2032 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = nomic-bert
llm_load_print_meta: vocab type       = WPM
llm_load_print_meta: n_vocab          = 30522
llm_load_print_meta: n_merges         = 0
llm_load_print_meta: vocab_only       = 0
llm_load_print_meta: n_ctx_train      = 2048
llm_load_print_meta: n_embd           = 768
llm_load_print_meta: n_layer          = 12
llm_load_print_meta: n_head           = 12
llm_load_print_meta: n_head_kv        = 12
llm_load_print_meta: n_rot            = 64
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_embd_head_k    = 64
llm_load_print_meta: n_embd_head_v    = 64
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: n_embd_k_gqa     = 768
llm_load_print_meta: n_embd_v_gqa     = 768
llm_load_print_meta: f_norm_eps       = 1.0e-12
llm_load_print_meta: f_norm_rms_eps   = 0.0e+00
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 0.0e+00
llm_load_print_meta: n_ff             = 3072
llm_load_print_meta: n_expert         = 0
llm_load_print_meta: n_expert_used    = 0
llm_load_print_meta: causal attn      = 0
llm_load_print_meta: pooling type     = 1
llm_load_print_meta: rope type        = 2
llm_load_print_meta: rope scaling     = linear
llm_load_print_meta: freq_base_train  = 1000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: n_ctx_orig_yarn  = 2048
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: ssm_dt_b_c_rms   = 0
llm_load_print_meta: model type       = 137M
llm_load_print_meta: model ftype      = F16
llm_load_print_meta: model params     = 136.73 M
llm_load_print_meta: model size       = 260.86 MiB (16.00 BPW) 
llm_load_print_meta: general.name     = nomic-embed-text-v1.5
llm_load_print_meta: BOS token        = 101 '[CLS]'
llm_load_print_meta: EOS token        = 102 '[SEP]'
llm_load_print_meta: UNK token        = 100 '[UNK]'
llm_load_print_meta: SEP token        = 102 '[SEP]'
llm_load_print_meta: PAD token        = 0 '[PAD]'
llm_load_print_meta: CLS token        = 101 '[CLS]'
llm_load_print_meta: MASK token       = 103 '[MASK]'
llm_load_print_meta: LF token         = 0 '[PAD]'
llm_load_print_meta: EOG token        = 102 '[SEP]'
llm_load_print_meta: max token length = 21
llm_load_tensors: ggml ctx size =    0.10 MiB
ggml_backend_metal_log_allocated_size: allocated buffer, size =   260.88 MiB, (  260.94 / 21845.34)
llm_load_tensors: offloading 12 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 13/13 layers to GPU
llm_load_tensors:        CPU buffer size =    44.72 MiB
llm_load_tensors:      Metal buffer size =   260.87 MiB
llama_new_context_with_model: n_ctx      = 8192
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 1000.0
llama_new_context_with_model: freq_scale = 1
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_init: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)
ggml_metal_init: simdgroup reduction support   = true
ggml_metal_init: simdgroup matrix mul. support = true
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB
llama_kv_cache_init:      Metal KV buffer size =   288.00 MiB
llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
llama_new_context_with_model:      Metal compute buffer size =    23.00 MiB
llama_new_context_with_model:        CPU compute buffer size =     3.50 MiB
llama_new_context_with_model: graph nodes  = 453
llama_new_context_with_model: graph splits = 2
time=2025-05-08T20:14:13.695+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server loading model"
time=2025-05-08T20:14:13.695+05:30 level=DEBUG source=server.go:632 msg="model load progress 1.00"
DEBUG [initialize] initializing slots | n_slots=1 tid="0x1f53f3240" timestamp=1746715453
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=0 tid="0x1f53f3240" timestamp=1746715453
INFO [main] model loaded | tid="0x1f53f3240" timestamp=1746715453
DEBUG [update_slots] all slots are idle and system prompt is empty, clear the KV cache | tid="0x1f53f3240" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=0 tid="0x1f53f3240" timestamp=1746715453
time=2025-05-08T20:14:13.947+05:30 level=INFO source=server.go:626 msg="llama runner started in 0.50 seconds"
time=2025-05-08T20:14:13.947+05:30 level=DEBUG source=sched.go:462 msg="finished setting up runner" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=1 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64773 status=200 tid="0x16b8d3000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=2 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64774 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=3 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64774 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=4 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64774 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=5 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64775 status=200 tid="0x16b9eb000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=6 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64775 status=200 tid="0x16b9eb000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=7 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64776 status=200 tid="0x16ba77000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=8 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64776 status=200 tid="0x16ba77000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=9 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64776 status=200 tid="0x16ba77000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=10 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64777 status=200 tid="0x16bb03000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=11 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64777 status=200 tid="0x16bb03000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=12 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64778 status=200 tid="0x16bb8f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=13 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64778 status=200 tid="0x16bb8f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=14 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64778 status=200 tid="0x16bb8f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=15 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64779 status=200 tid="0x16bc1b000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=16 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64779 status=200 tid="0x16bc1b000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=17 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64780 status=200 tid="0x16bca7000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=18 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64780 status=200 tid="0x16bca7000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=19 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64780 status=200 tid="0x16bca7000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=20 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64781 status=200 tid="0x16bd33000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=21 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64781 status=200 tid="0x16bd33000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=22 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64782 status=200 tid="0x16b8d3000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=23 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64782 status=200 tid="0x16b8d3000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=24 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64782 status=200 tid="0x16b8d3000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=25 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64783 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=26 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64783 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=27 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64784 status=200 tid="0x16b9eb000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=28 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64784 status=200 tid="0x16b9eb000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=29 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64784 status=200 tid="0x16b9eb000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=30 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64785 status=200 tid="0x16ba77000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=31 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64785 status=200 tid="0x16ba77000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=32 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64786 status=200 tid="0x16bb03000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=33 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64786 status=200 tid="0x16bb03000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=34 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64786 status=200 tid="0x16bb03000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=35 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64787 status=200 tid="0x16bb8f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=36 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64787 status=200 tid="0x16bb8f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=37 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64788 status=200 tid="0x16bc1b000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=38 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64788 status=200 tid="0x16bc1b000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=39 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64788 status=200 tid="0x16bc1b000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=40 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64789 status=200 tid="0x16bca7000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=41 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64789 status=200 tid="0x16bca7000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=42 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64790 status=200 tid="0x16bd33000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=43 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64790 status=200 tid="0x16bd33000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=44 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64790 status=200 tid="0x16bd33000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=45 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64791 status=200 tid="0x16b8d3000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=46 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64791 status=200 tid="0x16b8d3000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=47 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64792 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=48 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64792 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=49 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64792 status=200 tid="0x16b95f000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=50 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64793 status=200 tid="0x16b9eb000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=51 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64793 status=200 tid="0x16b9eb000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=52 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64794 status=200 tid="0x16ba77000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=53 tid="0x1f53f3240" timestamp=1746715453
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64794 status=200 tid="0x16ba77000" timestamp=1746715453
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=54 tid="0x1f53f3240" timestamp=1746715453
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=55 tid="0x1f53f3240" timestamp=1746715453
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=55 tid="0x1f53f3240" timestamp=1746715453
DEBUG [update_slots] slot released | n_cache_tokens=368 n_ctx=8192 n_past=368 n_system_tokens=0 slot_id=0 task_id=55 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64794 status=200 tid="0x16ba77000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=58 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=59 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=59 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=364 n_ctx=8192 n_past=364 n_system_tokens=0 slot_id=0 task_id=59 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64795 status=200 tid="0x16bb03000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=62 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=63 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=63 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=388 n_ctx=8192 n_past=388 n_system_tokens=0 slot_id=0 task_id=63 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64795 status=200 tid="0x16bb03000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=66 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=67 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=67 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=421 n_ctx=8192 n_past=421 n_system_tokens=0 slot_id=0 task_id=67 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64796 status=200 tid="0x16bb8f000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=70 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=71 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=71 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=411 n_ctx=8192 n_past=411 n_system_tokens=0 slot_id=0 task_id=71 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64796 status=200 tid="0x16bb8f000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=74 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=75 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=75 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=487 n_ctx=8192 n_past=487 n_system_tokens=0 slot_id=0 task_id=75 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64796 status=200 tid="0x16bb8f000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=78 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=79 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=79 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=126 n_ctx=8192 n_past=126 n_system_tokens=0 slot_id=0 task_id=79 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64797 status=200 tid="0x16bc1b000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=82 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=83 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=83 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=395 n_ctx=8192 n_past=395 n_system_tokens=0 slot_id=0 task_id=83 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64797 status=200 tid="0x16bc1b000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=86 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=87 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=87 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=396 n_ctx=8192 n_past=396 n_system_tokens=0 slot_id=0 task_id=87 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64798 status=200 tid="0x16bca7000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=90 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=91 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=91 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=472 n_ctx=8192 n_past=472 n_system_tokens=0 slot_id=0 task_id=91 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64798 status=200 tid="0x16bca7000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=94 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=95 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=95 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=399 n_ctx=8192 n_past=399 n_system_tokens=0 slot_id=0 task_id=95 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64798 status=200 tid="0x16bca7000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=98 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=99 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=99 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=417 n_ctx=8192 n_past=417 n_system_tokens=0 slot_id=0 task_id=99 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64799 status=200 tid="0x16bd33000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=102 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=103 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=103 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=439 n_ctx=8192 n_past=439 n_system_tokens=0 slot_id=0 task_id=103 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64799 status=200 tid="0x16bd33000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=106 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=107 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=107 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=429 n_ctx=8192 n_past=429 n_system_tokens=0 slot_id=0 task_id=107 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64800 status=200 tid="0x16b8d3000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=110 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=111 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=111 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=179 n_ctx=8192 n_past=179 n_system_tokens=0 slot_id=0 task_id=111 tid="0x1f53f3240" timestamp=1746715454 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64800 status=200 tid="0x16b8d3000" timestamp=1746715454
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=114 tid="0x1f53f3240" timestamp=1746715454
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=115 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=115 tid="0x1f53f3240" timestamp=1746715454
DEBUG [update_slots] slot released | n_cache_tokens=391 n_ctx=8192 n_past=391 n_system_tokens=0 slot_id=0 task_id=115 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64800 status=200 tid="0x16b8d3000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=118 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=119 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=119 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=439 n_ctx=8192 n_past=439 n_system_tokens=0 slot_id=0 task_id=119 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64801 status=200 tid="0x16b95f000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=122 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=123 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=123 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=391 n_ctx=8192 n_past=391 n_system_tokens=0 slot_id=0 task_id=123 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64801 status=200 tid="0x16b95f000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=126 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=127 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=127 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=402 n_ctx=8192 n_past=402 n_system_tokens=0 slot_id=0 task_id=127 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64802 status=200 tid="0x16b9eb000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=130 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=131 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=131 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=140 n_ctx=8192 n_past=140 n_system_tokens=0 slot_id=0 task_id=131 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64802 status=200 tid="0x16b9eb000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=134 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=135 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=135 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=180 n_ctx=8192 n_past=180 n_system_tokens=0 slot_id=0 task_id=135 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64802 status=200 tid="0x16b9eb000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=138 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=139 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=139 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=55 n_ctx=8192 n_past=55 n_system_tokens=0 slot_id=0 task_id=139 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64803 status=200 tid="0x16ba77000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=142 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=143 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=143 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=60 n_ctx=8192 n_past=60 n_system_tokens=0 slot_id=0 task_id=143 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64803 status=200 tid="0x16ba77000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=146 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=147 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=147 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=69 n_ctx=8192 n_past=69 n_system_tokens=0 slot_id=0 task_id=147 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64804 status=200 tid="0x16bb03000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=150 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=151 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=151 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=262 n_ctx=8192 n_past=262 n_system_tokens=0 slot_id=0 task_id=151 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64804 status=200 tid="0x16bb03000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=154 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=155 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=155 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=70 n_ctx=8192 n_past=70 n_system_tokens=0 slot_id=0 task_id=155 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64804 status=200 tid="0x16bb03000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=158 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=159 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=159 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=395 n_ctx=8192 n_past=395 n_system_tokens=0 slot_id=0 task_id=159 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64805 status=200 tid="0x16bb8f000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=162 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=163 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=163 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=400 n_ctx=8192 n_past=400 n_system_tokens=0 slot_id=0 task_id=163 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64805 status=200 tid="0x16bb8f000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=166 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=167 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=167 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=372 n_ctx=8192 n_past=372 n_system_tokens=0 slot_id=0 task_id=167 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64806 status=200 tid="0x16bc1b000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=170 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=171 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=171 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=83 n_ctx=8192 n_past=83 n_system_tokens=0 slot_id=0 task_id=171 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64806 status=200 tid="0x16bc1b000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=174 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=175 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=175 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=31 n_ctx=8192 n_past=31 n_system_tokens=0 slot_id=0 task_id=175 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64806 status=200 tid="0x16bc1b000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=178 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=179 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=179 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=468 n_ctx=8192 n_past=468 n_system_tokens=0 slot_id=0 task_id=179 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64807 status=200 tid="0x16bca7000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=182 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=183 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=183 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=115 n_ctx=8192 n_past=115 n_system_tokens=0 slot_id=0 task_id=183 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64807 status=200 tid="0x16bca7000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=186 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=187 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=187 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=331 n_ctx=8192 n_past=331 n_system_tokens=0 slot_id=0 task_id=187 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64808 status=200 tid="0x16bd33000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=190 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=191 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=191 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=422 n_ctx=8192 n_past=422 n_system_tokens=0 slot_id=0 task_id=191 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64808 status=200 tid="0x16bd33000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=194 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=195 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=195 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=171 n_ctx=8192 n_past=171 n_system_tokens=0 slot_id=0 task_id=195 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64808 status=200 tid="0x16bd33000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=198 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=199 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=199 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=364 n_ctx=8192 n_past=364 n_system_tokens=0 slot_id=0 task_id=199 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64809 status=200 tid="0x16b8d3000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=202 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=203 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=203 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=434 n_ctx=8192 n_past=434 n_system_tokens=0 slot_id=0 task_id=203 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64809 status=200 tid="0x16b8d3000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=206 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=207 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=207 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=77 n_ctx=8192 n_past=77 n_system_tokens=0 slot_id=0 task_id=207 tid="0x1f53f3240" timestamp=1746715455 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64810 status=200 tid="0x16b95f000" timestamp=1746715455
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=210 tid="0x1f53f3240" timestamp=1746715455
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=211 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=211 tid="0x1f53f3240" timestamp=1746715455
DEBUG [update_slots] slot released | n_cache_tokens=169 n_ctx=8192 n_past=169 n_system_tokens=0 slot_id=0 task_id=211 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64810 status=200 tid="0x16b95f000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=214 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=215 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=215 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=279 n_ctx=8192 n_past=279 n_system_tokens=0 slot_id=0 task_id=215 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64810 status=200 tid="0x16b95f000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=218 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=219 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=219 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=242 n_ctx=8192 n_past=242 n_system_tokens=0 slot_id=0 task_id=219 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64811 status=200 tid="0x16b9eb000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=222 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=223 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=223 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=393 n_ctx=8192 n_past=393 n_system_tokens=0 slot_id=0 task_id=223 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64811 status=200 tid="0x16b9eb000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=226 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=227 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=227 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=344 n_ctx=8192 n_past=344 n_system_tokens=0 slot_id=0 task_id=227 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64812 status=200 tid="0x16ba77000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=230 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=231 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=231 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=129 n_ctx=8192 n_past=129 n_system_tokens=0 slot_id=0 task_id=231 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64812 status=200 tid="0x16ba77000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=234 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=235 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=235 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=319 n_ctx=8192 n_past=319 n_system_tokens=0 slot_id=0 task_id=235 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64812 status=200 tid="0x16ba77000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=238 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=239 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=239 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=356 n_ctx=8192 n_past=356 n_system_tokens=0 slot_id=0 task_id=239 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64813 status=200 tid="0x16bb03000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=242 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=243 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=243 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=356 n_ctx=8192 n_past=356 n_system_tokens=0 slot_id=0 task_id=243 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64813 status=200 tid="0x16bb03000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=246 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=247 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=247 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=429 n_ctx=8192 n_past=429 n_system_tokens=0 slot_id=0 task_id=247 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64814 status=200 tid="0x16bb8f000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=250 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=251 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=251 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=319 n_ctx=8192 n_past=319 n_system_tokens=0 slot_id=0 task_id=251 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64814 status=200 tid="0x16bb8f000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=254 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=255 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=255 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=319 n_ctx=8192 n_past=319 n_system_tokens=0 slot_id=0 task_id=255 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64814 status=200 tid="0x16bb8f000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=258 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=259 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=259 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=389 n_ctx=8192 n_past=389 n_system_tokens=0 slot_id=0 task_id=259 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64815 status=200 tid="0x16bc1b000" timestamp=1746715456
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=262 tid="0x1f53f3240" timestamp=1746715456
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=263 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=263 tid="0x1f53f3240" timestamp=1746715456
DEBUG [update_slots] slot released | n_cache_tokens=87 n_ctx=8192 n_past=87 n_system_tokens=0 slot_id=0 task_id=263 tid="0x1f53f3240" timestamp=1746715456 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64815 status=200 tid="0x16bc1b000" timestamp=1746715456
[GIN] 2025/05/08 - 20:14:16 | 200 |  3.517634875s |       127.0.0.1 | POST     "/api/embed"
time=2025-05-08T20:14:16.678+05:30 level=DEBUG source=sched.go:466 msg="context for request finished"
time=2025-05-08T20:14:16.678+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 duration=5m0s
time=2025-05-08T20:14:16.678+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 refCount=0
[GIN] 2025/05/08 - 20:15:11 | 200 |      33.292µs |       127.0.0.1 | GET      "/api/version"
[GIN] 2025/05/08 - 20:15:17 | 200 |      22.458µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:15:17 | 200 |       16.75µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/08 - 20:16:15 | 200 |   21.202042ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/08 - 20:16:15 | 200 |   18.783916ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/08 - 20:16:15 | 200 |       3.873ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:16:15 | 200 |    6.238083ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:16:15 | 200 |    3.493542ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:16:15 | 200 |    5.373041ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:16:15 | 200 |    4.510208ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:16:15 | 200 |    8.004084ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:16:15 | 200 |    8.936416ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:16:15 | 200 |   18.140417ms |       127.0.0.1 | POST     "/api/show"
time=2025-05-08T20:16:17.069+05:30 level=DEBUG source=sched.go:575 msg="evaluating already loaded" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=266 tid="0x1f53f3240" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=267 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64849 status=200 tid="0x16bca7000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=268 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64849 status=200 tid="0x16bca7000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=269 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64850 status=200 tid="0x16bd33000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=270 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64850 status=200 tid="0x16bd33000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=271 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64851 status=200 tid="0x16b8d3000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=272 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64851 status=200 tid="0x16b8d3000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=273 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64851 status=200 tid="0x16b8d3000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=274 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64852 status=200 tid="0x16b95f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=275 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64852 status=200 tid="0x16b95f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=276 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64853 status=200 tid="0x16b9eb000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=277 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64853 status=200 tid="0x16b9eb000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=278 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64853 status=200 tid="0x16b9eb000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=279 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64854 status=200 tid="0x16ba77000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=280 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64854 status=200 tid="0x16ba77000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=281 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64855 status=200 tid="0x16bb03000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=282 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64855 status=200 tid="0x16bb03000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=283 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64855 status=200 tid="0x16bb03000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=284 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64856 status=200 tid="0x16bb8f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=285 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64856 status=200 tid="0x16bb8f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=286 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64857 status=200 tid="0x16bc1b000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=287 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64857 status=200 tid="0x16bc1b000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=288 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64857 status=200 tid="0x16bc1b000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=289 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64858 status=200 tid="0x16bca7000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=290 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64858 status=200 tid="0x16bca7000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=291 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64859 status=200 tid="0x16bd33000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=292 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64859 status=200 tid="0x16bd33000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=293 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64859 status=200 tid="0x16bd33000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=294 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64860 status=200 tid="0x16b8d3000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=295 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64860 status=200 tid="0x16b8d3000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=296 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64861 status=200 tid="0x16b95f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=297 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64861 status=200 tid="0x16b95f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=298 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64861 status=200 tid="0x16b95f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=299 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64862 status=200 tid="0x16b9eb000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=300 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64862 status=200 tid="0x16b9eb000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=301 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64863 status=200 tid="0x16ba77000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=302 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64863 status=200 tid="0x16ba77000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=303 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64863 status=200 tid="0x16ba77000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=304 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64864 status=200 tid="0x16bb03000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=305 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64864 status=200 tid="0x16bb03000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=306 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64865 status=200 tid="0x16bb8f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=307 tid="0x1f53f3240" timestamp=1746715577
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=64865 status=200 tid="0x16bb8f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=308 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=309 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=309 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=439 n_ctx=8192 n_past=439 n_system_tokens=0 slot_id=0 task_id=309 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64865 status=200 tid="0x16bb8f000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=312 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=313 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=313 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=242 n_ctx=8192 n_past=242 n_system_tokens=0 slot_id=0 task_id=313 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64866 status=200 tid="0x16bc1b000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=316 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=317 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=317 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=391 n_ctx=8192 n_past=391 n_system_tokens=0 slot_id=0 task_id=317 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64866 status=200 tid="0x16bc1b000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=320 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=321 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=321 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=391 n_ctx=8192 n_past=391 n_system_tokens=0 slot_id=0 task_id=321 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64867 status=200 tid="0x16bca7000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=324 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=325 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=325 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=388 n_ctx=8192 n_past=388 n_system_tokens=0 slot_id=0 task_id=325 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64867 status=200 tid="0x16bca7000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=328 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=329 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=329 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=487 n_ctx=8192 n_past=487 n_system_tokens=0 slot_id=0 task_id=329 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64867 status=200 tid="0x16bca7000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=332 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=333 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=333 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=429 n_ctx=8192 n_past=429 n_system_tokens=0 slot_id=0 task_id=333 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64868 status=200 tid="0x16bd33000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=336 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=337 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=337 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=396 n_ctx=8192 n_past=396 n_system_tokens=0 slot_id=0 task_id=337 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64868 status=200 tid="0x16bd33000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=340 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=341 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=341 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=417 n_ctx=8192 n_past=417 n_system_tokens=0 slot_id=0 task_id=341 tid="0x1f53f3240" timestamp=1746715577 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64869 status=200 tid="0x16b8d3000" timestamp=1746715577
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=344 tid="0x1f53f3240" timestamp=1746715577
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=345 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=345 tid="0x1f53f3240" timestamp=1746715577
DEBUG [update_slots] slot released | n_cache_tokens=389 n_ctx=8192 n_past=389 n_system_tokens=0 slot_id=0 task_id=345 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64869 status=200 tid="0x16b8d3000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=348 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=349 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=349 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=434 n_ctx=8192 n_past=434 n_system_tokens=0 slot_id=0 task_id=349 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64869 status=200 tid="0x16b8d3000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=352 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=353 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=353 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=344 n_ctx=8192 n_past=344 n_system_tokens=0 slot_id=0 task_id=353 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64870 status=200 tid="0x16b95f000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=356 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=357 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=357 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=393 n_ctx=8192 n_past=393 n_system_tokens=0 slot_id=0 task_id=357 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64870 status=200 tid="0x16b95f000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=360 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=361 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=361 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=472 n_ctx=8192 n_past=472 n_system_tokens=0 slot_id=0 task_id=361 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64871 status=200 tid="0x16b9eb000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=364 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=365 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=365 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=399 n_ctx=8192 n_past=399 n_system_tokens=0 slot_id=0 task_id=365 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64871 status=200 tid="0x16b9eb000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=368 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=369 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=369 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=439 n_ctx=8192 n_past=439 n_system_tokens=0 slot_id=0 task_id=369 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64871 status=200 tid="0x16b9eb000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=372 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=373 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=373 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=400 n_ctx=8192 n_past=400 n_system_tokens=0 slot_id=0 task_id=373 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64872 status=200 tid="0x16ba77000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=376 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=377 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=377 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=468 n_ctx=8192 n_past=468 n_system_tokens=0 slot_id=0 task_id=377 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64872 status=200 tid="0x16ba77000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=380 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=381 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=381 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=422 n_ctx=8192 n_past=422 n_system_tokens=0 slot_id=0 task_id=381 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64873 status=200 tid="0x16bb03000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=384 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=385 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=385 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=364 n_ctx=8192 n_past=364 n_system_tokens=0 slot_id=0 task_id=385 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64873 status=200 tid="0x16bb03000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=388 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=389 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=389 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=129 n_ctx=8192 n_past=129 n_system_tokens=0 slot_id=0 task_id=389 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64873 status=200 tid="0x16bb03000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=392 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=393 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=393 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=319 n_ctx=8192 n_past=319 n_system_tokens=0 slot_id=0 task_id=393 tid="0x1f53f3240" timestamp=1746715578 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64874 status=200 tid="0x16bb8f000" timestamp=1746715578
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=396 tid="0x1f53f3240" timestamp=1746715578
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=397 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=397 tid="0x1f53f3240" timestamp=1746715578
DEBUG [update_slots] slot released | n_cache_tokens=429 n_ctx=8192 n_past=429 n_system_tokens=0 slot_id=0 task_id=397 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64874 status=200 tid="0x16bb8f000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=400 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=401 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=401 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=179 n_ctx=8192 n_past=179 n_system_tokens=0 slot_id=0 task_id=401 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64875 status=200 tid="0x16bc1b000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=404 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=405 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=405 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=319 n_ctx=8192 n_past=319 n_system_tokens=0 slot_id=0 task_id=405 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64875 status=200 tid="0x16bc1b000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=408 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=409 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=409 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=319 n_ctx=8192 n_past=319 n_system_tokens=0 slot_id=0 task_id=409 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64875 status=200 tid="0x16bc1b000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=412 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=413 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=413 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=87 n_ctx=8192 n_past=87 n_system_tokens=0 slot_id=0 task_id=413 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64876 status=200 tid="0x16bca7000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=416 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=417 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=417 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=356 n_ctx=8192 n_past=356 n_system_tokens=0 slot_id=0 task_id=417 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64876 status=200 tid="0x16bca7000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=420 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=421 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=421 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=356 n_ctx=8192 n_past=356 n_system_tokens=0 slot_id=0 task_id=421 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64877 status=200 tid="0x16bd33000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=424 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=425 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=425 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=77 n_ctx=8192 n_past=77 n_system_tokens=0 slot_id=0 task_id=425 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64877 status=200 tid="0x16bd33000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=428 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=429 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=429 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=31 n_ctx=8192 n_past=31 n_system_tokens=0 slot_id=0 task_id=429 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64877 status=200 tid="0x16bd33000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=432 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=433 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=433 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=70 n_ctx=8192 n_past=70 n_system_tokens=0 slot_id=0 task_id=433 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64878 status=200 tid="0x16b8d3000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=436 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=437 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=437 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=262 n_ctx=8192 n_past=262 n_system_tokens=0 slot_id=0 task_id=437 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64878 status=200 tid="0x16b8d3000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=440 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=441 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=441 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=421 n_ctx=8192 n_past=421 n_system_tokens=0 slot_id=0 task_id=441 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64879 status=200 tid="0x16b95f000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=444 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=445 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=445 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=364 n_ctx=8192 n_past=364 n_system_tokens=0 slot_id=0 task_id=445 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64879 status=200 tid="0x16b95f000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=448 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=449 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=449 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=411 n_ctx=8192 n_past=411 n_system_tokens=0 slot_id=0 task_id=449 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64879 status=200 tid="0x16b95f000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=452 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=453 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=453 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=368 n_ctx=8192 n_past=368 n_system_tokens=0 slot_id=0 task_id=453 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64880 status=200 tid="0x16b9eb000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=456 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=457 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=457 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=395 n_ctx=8192 n_past=395 n_system_tokens=0 slot_id=0 task_id=457 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64880 status=200 tid="0x16b9eb000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=460 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=461 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=461 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=395 n_ctx=8192 n_past=395 n_system_tokens=0 slot_id=0 task_id=461 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64881 status=200 tid="0x16ba77000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=464 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=465 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=465 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=402 n_ctx=8192 n_past=402 n_system_tokens=0 slot_id=0 task_id=465 tid="0x1f53f3240" timestamp=1746715579 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64881 status=200 tid="0x16ba77000" timestamp=1746715579
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=468 tid="0x1f53f3240" timestamp=1746715579
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=469 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=469 tid="0x1f53f3240" timestamp=1746715579
DEBUG [update_slots] slot released | n_cache_tokens=372 n_ctx=8192 n_past=372 n_system_tokens=0 slot_id=0 task_id=469 tid="0x1f53f3240" timestamp=1746715580 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=64881 status=200 tid="0x16ba77000" timestamp=1746715580
[GIN] 2025/05/08 - 20:16:20 | 200 |  2.949523417s |       127.0.0.1 | POST     "/api/embed"
time=2025-05-08T20:16:20.018+05:30 level=DEBUG source=sched.go:407 msg="context for request finished"
time=2025-05-08T20:16:20.018+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 duration=5m0s
time=2025-05-08T20:16:20.018+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 refCount=0
[GIN] 2025/05/08 - 20:17:38 | 200 |    6.628625ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:17:38 | 200 |      6.5225ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:17:38 | 200 |     7.80275ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:17:38 | 200 |   19.642959ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:18:15 | 200 |   14.881167ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:18:15 | 200 |    18.84975ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:18:15 | 200 |   19.416291ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:18:15 | 200 |   24.225458ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:18:31 | 200 |      24.834µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:18:31 | 200 |      19.292µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/08 - 20:19:22 | 200 |    3.739041ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:19:22 | 200 |    4.012333ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:19:22 | 200 |      5.7085ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:19:22 | 200 |    5.923125ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:19:56 | 200 |      19.375µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:19:56 | 200 |      25.584µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/08 - 20:20:02 | 200 |       30.75µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:20:02 | 200 |    1.556875ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/08 - 20:20:11 | 200 |      18.125µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:20:11 | 200 |      6.1415ms |       127.0.0.1 | POST     "/api/show"
time=2025-05-08T20:20:11.396+05:30 level=DEBUG source=sched.go:496 msg="gpu reported" gpu=0 library=metal available="21.3 GiB"
time=2025-05-08T20:20:11.396+05:30 level=INFO source=sched.go:507 msg="updated VRAM based on existing loaded models" gpu=0 library=metal total="21.3 GiB" available="20.5 GiB"
time=2025-05-08T20:20:11.396+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[20.5 GiB]"
time=2025-05-08T20:20:11.397+05:30 level=INFO source=sched.go:714 msg="new model will fit in available VRAM in single GPU, loading" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 gpu=0 parallel=4 available=21999629312 required="7.3 GiB"
time=2025-05-08T20:20:11.397+05:30 level=DEBUG source=sched.go:249 msg="new model fits with existing models, loading"
time=2025-05-08T20:20:11.397+05:30 level=INFO source=server.go:105 msg="system memory" total="32.0 GiB" free="20.4 GiB" free_swap="0 B"
time=2025-05-08T20:20:11.397+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[20.5 GiB]"
time=2025-05-08T20:20:11.397+05:30 level=INFO source=memory.go:326 msg="offload to metal" layers.requested=-1 layers.model=41 layers.offload=41 layers.split="" memory.available="[20.5 GiB]" memory.gpu_overhead="0 B" memory.required.full="7.3 GiB" memory.required.partial="7.3 GiB" memory.required.kv="1.2 GiB" memory.required.allocations="[7.3 GiB]" memory.weights.total="5.7 GiB" memory.weights.repeating="5.5 GiB" memory.weights.nonrepeating="157.5 MiB" memory.graph.full="853.3 MiB" memory.graph.partial="853.3 MiB"
time=2025-05-08T20:20:11.397+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-08T20:20:11.398+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:20:11.398+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:20:11.398+05:30 level=INFO source=server.go:388 msg="starting llama server" cmd="/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server --model /Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 --ctx-size 8192 --batch-size 512 --embedding --n-gpu-layers 41 --verbose --threads 8 --parallel 4 --port 65409"
time=2025-05-08T20:20:11.398+05:30 level=DEBUG source=server.go:405 msg=subprocess environment="[PATH=/Users/harsh/Desktop/Continue.dev-Granite-manual-test-cases/granite/bin:/Users/harsh/.pyenv/shims:/Users/harsh/.pyenv/bin:/Users/harsh/.pyenv/bin:/opt/homebrew/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/harsh/.local/bin LD_LIBRARY_PATH=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal]"
time=2025-05-08T20:20:11.400+05:30 level=INFO source=sched.go:449 msg="loaded runners" count=2
time=2025-05-08T20:20:11.400+05:30 level=INFO source=server.go:587 msg="waiting for llama runner to start responding"
time=2025-05-08T20:20:11.400+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server error"
INFO [main] starting c++ runner | tid="0x1f53f3240" timestamp=1746715811
INFO [main] build info | build=3871 commit="f37ceeaa" tid="0x1f53f3240" timestamp=1746715811
INFO [main] system info | n_threads=8 n_threads_batch=8 system_info="AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | " tid="0x1f53f3240" timestamp=1746715811 total_threads=10
INFO [main] HTTP server listening | hostname="127.0.0.1" n_threads_http="9" port="65409" tid="0x1f53f3240" timestamp=1746715811
llama_model_loader: loaded meta data with 40 key-value pairs and 362 tensors from /Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = granite
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Granite 3.2 8b Instruct
llama_model_loader: - kv   3:                           general.finetune str              = instruct
llama_model_loader: - kv   4:                           general.basename str              = granite-3.2
llama_model_loader: - kv   5:                         general.size_label str              = 8B
llama_model_loader: - kv   6:                            general.license str              = apache-2.0
llama_model_loader: - kv   7:                   general.base_model.count u32              = 1
llama_model_loader: - kv   8:                  general.base_model.0.name str              = Granite 3.1 8b Instruct
llama_model_loader: - kv   9:          general.base_model.0.organization str              = Ibm Granite
llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/ibm-granite/gr...
llama_model_loader: - kv  11:                               general.tags arr[str,3]       = ["language", "granite-3.2", "text-gen...
llama_model_loader: - kv  12:                        granite.block_count u32              = 40
llama_model_loader: - kv  13:                     granite.context_length u32              = 131072
llama_model_loader: - kv  14:                   granite.embedding_length u32              = 4096
llama_model_loader: - kv  15:                granite.feed_forward_length u32              = 12800
llama_model_loader: - kv  16:               granite.attention.head_count u32              = 32
llama_model_loader: - kv  17:            granite.attention.head_count_kv u32              = 8
llama_model_loader: - kv  18:                     granite.rope.freq_base f32              = 10000000.000000
llama_model_loader: - kv  19:   granite.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  20:                          general.file_type u32              = 15
llama_model_loader: - kv  21:                         granite.vocab_size u32              = 49155
llama_model_loader: - kv  22:               granite.rope.dimension_count u32              = 128
llama_model_loader: - kv  23:                    granite.attention.scale f32              = 0.007812
llama_model_loader: - kv  24:                    granite.embedding_scale f32              = 12.000000
llama_model_loader: - kv  25:                     granite.residual_scale f32              = 0.220000
llama_model_loader: - kv  26:                        granite.logit_scale f32              = 16.000000
llama_model_loader: - kv  27:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  28:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  29:                      tokenizer.ggml.tokens arr[str,49155]   = ["<|end_of_text|>", "<fim_prefix>", "...
llama_model_loader: - kv  30:                  tokenizer.ggml.token_type arr[i32,49155]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  31:                      tokenizer.ggml.merges arr[str,48891]   = ["Ġ Ġ", "ĠĠ ĠĠ", "ĠĠĠĠ ĠĠ...
llama_model_loader: - kv  32:                tokenizer.ggml.bos_token_id u32              = 0
llama_model_loader: - kv  33:                tokenizer.ggml.eos_token_id u32              = 0
llama_model_loader: - kv  34:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 0
llama_model_loader: - kv  36:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  37:                    tokenizer.chat_template str              = {%- if messages[0]['role'] == 'system...
llama_model_loader: - kv  38:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  39:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   81 tensors
llama_model_loader: - type q4_K:  240 tensors
llama_model_loader: - type q6_K:   41 tensors
llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
llm_load_vocab: special tokens cache size = 22
llm_load_vocab: token to piece cache size = 0.2826 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = granite
llm_load_print_meta: vocab type       = BPE
llm_load_print_meta: n_vocab          = 49155
llm_load_print_meta: n_merges         = 48891
llm_load_print_meta: vocab_only       = 0
llm_load_print_meta: n_ctx_train      = 131072
llm_load_print_meta: n_embd           = 4096
llm_load_print_meta: n_layer          = 40
llm_load_print_meta: n_head           = 32
llm_load_print_meta: n_head_kv        = 8
llm_load_print_meta: n_rot            = 128
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_embd_head_k    = 128
llm_load_print_meta: n_embd_head_v    = 128
llm_load_print_meta: n_gqa            = 4
llm_load_print_meta: n_embd_k_gqa     = 1024
llm_load_print_meta: n_embd_v_gqa     = 1024
llm_load_print_meta: f_norm_eps       = 0.0e+00
llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 1.6e+01
llm_load_print_meta: n_ff             = 12800
llm_load_print_meta: n_expert         = 0
llm_load_print_meta: n_expert_used    = 0
llm_load_print_meta: causal attn      = 1
llm_load_print_meta: pooling type     = 0
llm_load_print_meta: rope type        = 0
llm_load_print_meta: rope scaling     = linear
llm_load_print_meta: freq_base_train  = 10000000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: n_ctx_orig_yarn  = 131072
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: ssm_dt_b_c_rms   = 0
llm_load_print_meta: model type       = 3B
llm_load_print_meta: model ftype      = Q4_K - Medium
llm_load_print_meta: model params     = 8.17 B
llm_load_print_meta: model size       = 4.60 GiB (4.84 BPW) 
llm_load_print_meta: general.name     = Granite 3.2 8b Instruct
llm_load_print_meta: BOS token        = 0 '<|end_of_text|>'
llm_load_print_meta: EOS token        = 0 '<|end_of_text|>'
llm_load_print_meta: UNK token        = 0 '<|end_of_text|>'
llm_load_print_meta: PAD token        = 0 '<|end_of_text|>'
llm_load_print_meta: LF token         = 145 'Ä'
llm_load_print_meta: EOG token        = 0 '<|end_of_text|>'
llm_load_print_meta: max token length = 512
llm_load_print_meta: f_embedding_scale = 12.000000
llm_load_print_meta: f_residual_scale  = 0.220000
llm_load_print_meta: f_attention_scale = 0.007812
llm_load_tensors: ggml ctx size =    0.34 MiB
ggml_backend_metal_log_allocated_size: allocated buffer, size =  4712.23 MiB, ( 4712.30 / 21845.34)
llm_load_tensors: offloading 40 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 41/41 layers to GPU
llm_load_tensors:        CPU buffer size =   157.51 MiB
llm_load_tensors:      Metal buffer size =  4712.22 MiB
llama_new_context_with_model: n_ctx      = 8192
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 10000000.0
llama_new_context_with_model: freq_scale = 1
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_init: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)
ggml_metal_init: simdgroup reduction support   = true
ggml_metal_init: simdgroup matrix mul. support = true
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB
time=2025-05-08T20:20:11.652+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server loading model"
time=2025-05-08T20:20:11.652+05:30 level=DEBUG source=server.go:632 msg="model load progress 1.00"
llama_kv_cache_init:      Metal KV buffer size =  1280.00 MiB
llama_new_context_with_model: KV self size  = 1280.00 MiB, K (f16):  640.00 MiB, V (f16):  640.00 MiB
llama_new_context_with_model:        CPU  output buffer size =     0.81 MiB
llama_new_context_with_model:      Metal compute buffer size =   560.00 MiB
llama_new_context_with_model:        CPU compute buffer size =    24.01 MiB
llama_new_context_with_model: graph nodes  = 1368
llama_new_context_with_model: graph splits = 2
time=2025-05-08T20:20:11.905+05:30 level=DEBUG source=server.go:635 msg="model load completed, waiting for server to become available" status="llm server loading model"
DEBUG [initialize] initializing slots | n_slots=4 tid="0x1f53f3240" timestamp=1746715813
DEBUG [initialize] new slot | n_ctx_slot=2048 slot_id=0 tid="0x1f53f3240" timestamp=1746715813
DEBUG [initialize] new slot | n_ctx_slot=2048 slot_id=1 tid="0x1f53f3240" timestamp=1746715813
DEBUG [initialize] new slot | n_ctx_slot=2048 slot_id=2 tid="0x1f53f3240" timestamp=1746715813
DEBUG [initialize] new slot | n_ctx_slot=2048 slot_id=3 tid="0x1f53f3240" timestamp=1746715813
INFO [main] model loaded | tid="0x1f53f3240" timestamp=1746715813
DEBUG [update_slots] all slots are idle and system prompt is empty, clear the KV cache | tid="0x1f53f3240" timestamp=1746715813
DEBUG [process_single_task] slot data | n_idle_slots=4 n_processing_slots=0 task_id=0 tid="0x1f53f3240" timestamp=1746715813
time=2025-05-08T20:20:13.669+05:30 level=INFO source=server.go:626 msg="llama runner started in 2.27 seconds"
time=2025-05-08T20:20:13.669+05:30 level=DEBUG source=sched.go:462 msg="finished setting up runner" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
[GIN] 2025/05/08 - 20:20:13 | 200 |   2.28646775s |       127.0.0.1 | POST     "/api/generate"
time=2025-05-08T20:20:13.669+05:30 level=DEBUG source=sched.go:466 msg="context for request finished"
time=2025-05-08T20:20:13.669+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 duration=5m0s
time=2025-05-08T20:20:13.669+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 refCount=0
time=2025-05-08T20:21:20.019+05:30 level=DEBUG source=sched.go:341 msg="timer expired, expiring to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:21:20.019+05:30 level=DEBUG source=sched.go:360 msg="runner expired event received" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:21:20.019+05:30 level=DEBUG source=sched.go:375 msg="got lock to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:21:20.019+05:30 level=DEBUG source=server.go:1086 msg="stopping llama server"
time=2025-05-08T20:21:20.019+05:30 level=DEBUG source=server.go:1092 msg="waiting for llama server to exit"
time=2025-05-08T20:21:20.041+05:30 level=DEBUG source=server.go:1096 msg="llama server stopped"
time=2025-05-08T20:21:20.041+05:30 level=DEBUG source=sched.go:380 msg="runner released" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:21:20.041+05:30 level=DEBUG source=sched.go:384 msg="sending an unloaded event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:21:20.041+05:30 level=DEBUG source=sched.go:308 msg="ignoring unload event with no pending requests"
[GIN] 2025/05/08 - 20:22:46 | 200 |    5.859917ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:22:46 | 200 |    6.436584ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:22:46 | 200 |    7.655833ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:22:46 | 200 |   18.038084ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |   25.494125ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |   25.150875ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |    10.48775ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |   12.630375ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |   15.479292ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |   14.734708ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |   24.949667ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:24:30 | 200 |   27.576792ms |       127.0.0.1 | POST     "/api/show"
time=2025-05-08T20:24:35.928+05:30 level=DEBUG source=sched.go:496 msg="gpu reported" gpu=0 library=metal available="21.3 GiB"
time=2025-05-08T20:24:35.928+05:30 level=INFO source=sched.go:507 msg="updated VRAM based on existing loaded models" gpu=0 library=metal total="21.3 GiB" available="14.0 GiB"
time=2025-05-08T20:24:35.928+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[14.0 GiB]"
time=2025-05-08T20:24:35.928+05:30 level=INFO source=sched.go:714 msg="new model will fit in available VRAM in single GPU, loading" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 gpu=0 parallel=1 available=15031305035 required="864.9 MiB"
time=2025-05-08T20:24:35.928+05:30 level=DEBUG source=sched.go:249 msg="new model fits with existing models, loading"
time=2025-05-08T20:24:35.929+05:30 level=INFO source=server.go:105 msg="system memory" total="32.0 GiB" free="16.7 GiB" free_swap="0 B"
time=2025-05-08T20:24:35.929+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[14.0 GiB]"
time=2025-05-08T20:24:35.929+05:30 level=INFO source=memory.go:326 msg="offload to metal" layers.requested=-1 layers.model=13 layers.offload=13 layers.split="" memory.available="[14.0 GiB]" memory.gpu_overhead="0 B" memory.required.full="864.9 MiB" memory.required.partial="864.9 MiB" memory.required.kv="24.0 MiB" memory.required.allocations="[864.9 MiB]" memory.weights.total="240.1 MiB" memory.weights.repeating="195.4 MiB" memory.weights.nonrepeating="44.7 MiB" memory.graph.full="48.0 MiB" memory.graph.partial="48.0 MiB"
time=2025-05-08T20:24:35.929+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-08T20:24:35.931+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:24:35.937+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:24:35.939+05:30 level=INFO source=server.go:388 msg="starting llama server" cmd="/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server --model /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 --ctx-size 8192 --batch-size 512 --embedding --n-gpu-layers 13 --verbose --threads 8 --parallel 1 --port 49337"
time=2025-05-08T20:24:35.939+05:30 level=DEBUG source=server.go:405 msg=subprocess environment="[PATH=/Users/harsh/Desktop/Continue.dev-Granite-manual-test-cases/granite/bin:/Users/harsh/.pyenv/shims:/Users/harsh/.pyenv/bin:/Users/harsh/.pyenv/bin:/opt/homebrew/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/harsh/.local/bin LD_LIBRARY_PATH=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal]"
time=2025-05-08T20:24:35.944+05:30 level=INFO source=sched.go:449 msg="loaded runners" count=2
time=2025-05-08T20:24:35.944+05:30 level=INFO source=server.go:587 msg="waiting for llama runner to start responding"
time=2025-05-08T20:24:35.944+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server error"
INFO [main] starting c++ runner | tid="0x1f53f3240" timestamp=1746716075
INFO [main] build info | build=3871 commit="f37ceeaa" tid="0x1f53f3240" timestamp=1746716075
INFO [main] system info | n_threads=8 n_threads_batch=8 system_info="AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | " tid="0x1f53f3240" timestamp=1746716075 total_threads=10
INFO [main] HTTP server listening | hostname="127.0.0.1" n_threads_http="9" port="49337" tid="0x1f53f3240" timestamp=1746716075
llama_model_loader: loaded meta data with 24 key-value pairs and 112 tensors from /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = nomic-bert
llama_model_loader: - kv   1:                               general.name str              = nomic-embed-text-v1.5
llama_model_loader: - kv   2:                     nomic-bert.block_count u32              = 12
llama_model_loader: - kv   3:                  nomic-bert.context_length u32              = 2048
llama_model_loader: - kv   4:                nomic-bert.embedding_length u32              = 768
llama_model_loader: - kv   5:             nomic-bert.feed_forward_length u32              = 3072
llama_model_loader: - kv   6:            nomic-bert.attention.head_count u32              = 12
llama_model_loader: - kv   7:    nomic-bert.attention.layer_norm_epsilon f32              = 0.000000
llama_model_loader: - kv   8:                          general.file_type u32              = 1
llama_model_loader: - kv   9:                nomic-bert.attention.causal bool             = false
llama_model_loader: - kv  10:                    nomic-bert.pooling_type u32              = 1
llama_model_loader: - kv  11:                  nomic-bert.rope.freq_base f32              = 1000.000000
llama_model_loader: - kv  12:            tokenizer.ggml.token_type_count u32              = 2
llama_model_loader: - kv  13:                tokenizer.ggml.bos_token_id u32              = 101
llama_model_loader: - kv  14:                tokenizer.ggml.eos_token_id u32              = 102
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = bert
llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,30522]   = ["[PAD]", "[unused0]", "[unused1]", "...
llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 100
llama_model_loader: - kv  20:          tokenizer.ggml.seperator_token_id u32              = 102
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0
llama_model_loader: - kv  22:                tokenizer.ggml.cls_token_id u32              = 101
llama_model_loader: - kv  23:               tokenizer.ggml.mask_token_id u32              = 103
llama_model_loader: - type  f32:   51 tensors
llama_model_loader: - type  f16:   61 tensors
llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
llm_load_vocab: special tokens cache size = 5
llm_load_vocab: token to piece cache size = 0.2032 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = nomic-bert
llm_load_print_meta: vocab type       = WPM
llm_load_print_meta: n_vocab          = 30522
llm_load_print_meta: n_merges         = 0
llm_load_print_meta: vocab_only       = 0
llm_load_print_meta: n_ctx_train      = 2048
llm_load_print_meta: n_embd           = 768
llm_load_print_meta: n_layer          = 12
llm_load_print_meta: n_head           = 12
llm_load_print_meta: n_head_kv        = 12
llm_load_print_meta: n_rot            = 64
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_embd_head_k    = 64
llm_load_print_meta: n_embd_head_v    = 64
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: n_embd_k_gqa     = 768
llm_load_print_meta: n_embd_v_gqa     = 768
llm_load_print_meta: f_norm_eps       = 1.0e-12
llm_load_print_meta: f_norm_rms_eps   = 0.0e+00
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 0.0e+00
llm_load_print_meta: n_ff             = 3072
llm_load_print_meta: n_expert         = 0
llm_load_print_meta: n_expert_used    = 0
llm_load_print_meta: causal attn      = 0
llm_load_print_meta: pooling type     = 1
llm_load_print_meta: rope type        = 2
llm_load_print_meta: rope scaling     = linear
llm_load_print_meta: freq_base_train  = 1000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: n_ctx_orig_yarn  = 2048
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: ssm_dt_b_c_rms   = 0
llm_load_print_meta: model type       = 137M
llm_load_print_meta: model ftype      = F16
llm_load_print_meta: model params     = 136.73 M
llm_load_print_meta: model size       = 260.86 MiB (16.00 BPW) 
llm_load_print_meta: general.name     = nomic-embed-text-v1.5
llm_load_print_meta: BOS token        = 101 '[CLS]'
llm_load_print_meta: EOS token        = 102 '[SEP]'
llm_load_print_meta: UNK token        = 100 '[UNK]'
llm_load_print_meta: SEP token        = 102 '[SEP]'
llm_load_print_meta: PAD token        = 0 '[PAD]'
llm_load_print_meta: CLS token        = 101 '[CLS]'
llm_load_print_meta: MASK token       = 103 '[MASK]'
llm_load_print_meta: LF token         = 0 '[PAD]'
llm_load_print_meta: EOG token        = 102 '[SEP]'
llm_load_print_meta: max token length = 21
llm_load_tensors: ggml ctx size =    0.10 MiB
ggml_backend_metal_log_allocated_size: allocated buffer, size =   260.88 MiB, (  260.94 / 21845.34)
llm_load_tensors: offloading 12 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 13/13 layers to GPU
llm_load_tensors:        CPU buffer size =    44.72 MiB
llm_load_tensors:      Metal buffer size =   260.87 MiB
llama_new_context_with_model: n_ctx      = 8192
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 1000.0
llama_new_context_with_model: freq_scale = 1
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_init: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)
ggml_metal_init: simdgroup reduction support   = true
ggml_metal_init: simdgroup matrix mul. support = true
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB
llama_kv_cache_init:      Metal KV buffer size =   288.00 MiB
llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
llama_new_context_with_model:      Metal compute buffer size =    23.00 MiB
llama_new_context_with_model:        CPU compute buffer size =     3.50 MiB
llama_new_context_with_model: graph nodes  = 453
llama_new_context_with_model: graph splits = 2
DEBUG [initialize] initializing slots | n_slots=1 tid="0x1f53f3240" timestamp=1746716076
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=0 tid="0x1f53f3240" timestamp=1746716076
INFO [main] model loaded | tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] all slots are idle and system prompt is empty, clear the KV cache | tid="0x1f53f3240" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=0 tid="0x1f53f3240" timestamp=1746716076
time=2025-05-08T20:24:36.196+05:30 level=INFO source=server.go:626 msg="llama runner started in 0.25 seconds"
time=2025-05-08T20:24:36.196+05:30 level=DEBUG source=sched.go:462 msg="finished setting up runner" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=1 tid="0x1f53f3240" timestamp=1746716076
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=49341 status=200 tid="0x16db37000" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=2 tid="0x1f53f3240" timestamp=1746716076
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=49341 status=200 tid="0x16db37000" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=3 tid="0x1f53f3240" timestamp=1746716076
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=49342 status=200 tid="0x16dbc3000" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=4 tid="0x1f53f3240" timestamp=1746716076
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=49342 status=200 tid="0x16dbc3000" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=5 tid="0x1f53f3240" timestamp=1746716076
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=6 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=6 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] slot released | n_cache_tokens=253 n_ctx=8192 n_past=253 n_system_tokens=0 slot_id=0 task_id=6 tid="0x1f53f3240" timestamp=1746716076 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=49343 status=200 tid="0x16dc4f000" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=9 tid="0x1f53f3240" timestamp=1746716076
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=10 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=10 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] slot released | n_cache_tokens=382 n_ctx=8192 n_past=382 n_system_tokens=0 slot_id=0 task_id=10 tid="0x1f53f3240" timestamp=1746716076 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=49343 status=200 tid="0x16dc4f000" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=13 tid="0x1f53f3240" timestamp=1746716076
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=14 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=14 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] slot released | n_cache_tokens=406 n_ctx=8192 n_past=406 n_system_tokens=0 slot_id=0 task_id=14 tid="0x1f53f3240" timestamp=1746716076 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=49343 status=200 tid="0x16dc4f000" timestamp=1746716076
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=17 tid="0x1f53f3240" timestamp=1746716076
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=18 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=18 tid="0x1f53f3240" timestamp=1746716076
DEBUG [update_slots] slot released | n_cache_tokens=434 n_ctx=8192 n_past=434 n_system_tokens=0 slot_id=0 task_id=18 tid="0x1f53f3240" timestamp=1746716076 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=49346 status=200 tid="0x16dcdb000" timestamp=1746716076
[GIN] 2025/05/08 - 20:24:36 | 200 |  629.465166ms |       127.0.0.1 | POST     "/api/embed"
time=2025-05-08T20:24:36.535+05:30 level=DEBUG source=sched.go:466 msg="context for request finished"
time=2025-05-08T20:24:36.535+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 duration=5m0s
time=2025-05-08T20:24:36.535+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 refCount=0
time=2025-05-08T20:25:13.670+05:30 level=DEBUG source=sched.go:341 msg="timer expired, expiring to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:25:13.670+05:30 level=DEBUG source=sched.go:360 msg="runner expired event received" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:25:13.670+05:30 level=DEBUG source=sched.go:375 msg="got lock to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:25:13.670+05:30 level=DEBUG source=server.go:1086 msg="stopping llama server"
time=2025-05-08T20:25:13.670+05:30 level=DEBUG source=server.go:1092 msg="waiting for llama server to exit"
time=2025-05-08T20:25:13.770+05:30 level=DEBUG source=server.go:1096 msg="llama server stopped"
time=2025-05-08T20:25:13.770+05:30 level=DEBUG source=sched.go:380 msg="runner released" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:25:13.770+05:30 level=DEBUG source=sched.go:384 msg="sending an unloaded event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:25:13.770+05:30 level=DEBUG source=sched.go:308 msg="ignoring unload event with no pending requests"
[GIN] 2025/05/08 - 20:27:03 | 200 |   12.199917ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:27:03 | 200 |    14.84175ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:27:03 | 200 |    15.92925ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:27:03 | 200 |   21.847958ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:22 | 200 |   14.512542ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/08 - 20:28:22 | 200 |    4.939083ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/08 - 20:28:22 | 200 |   17.362334ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:22 | 200 |   17.243333ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:22 | 200 |    10.21075ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:22 | 200 |      6.7775ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:23 | 200 |     13.2335ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:23 | 200 |   17.475125ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:23 | 200 |   19.081583ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:28:23 | 200 |   18.186459ms |       127.0.0.1 | POST     "/api/show"
time=2025-05-08T20:28:27.496+05:30 level=DEBUG source=sched.go:496 msg="gpu reported" gpu=0 library=metal available="21.3 GiB"
time=2025-05-08T20:28:27.497+05:30 level=INFO source=sched.go:507 msg="updated VRAM based on existing loaded models" gpu=0 library=metal total="21.3 GiB" available="20.5 GiB"
time=2025-05-08T20:28:27.497+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[20.5 GiB]"
time=2025-05-08T20:28:27.497+05:30 level=INFO source=sched.go:714 msg="new model will fit in available VRAM in single GPU, loading" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 gpu=0 parallel=4 available=21999629312 required="13.7 GiB"
time=2025-05-08T20:28:27.497+05:30 level=DEBUG source=sched.go:249 msg="new model fits with existing models, loading"
time=2025-05-08T20:28:27.497+05:30 level=INFO source=server.go:105 msg="system memory" total="32.0 GiB" free="16.7 GiB" free_swap="0 B"
time=2025-05-08T20:28:27.497+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[20.5 GiB]"
time=2025-05-08T20:28:27.498+05:30 level=INFO source=memory.go:326 msg="offload to metal" layers.requested=-1 layers.model=41 layers.offload=41 layers.split="" memory.available="[20.5 GiB]" memory.gpu_overhead="0 B" memory.required.full="13.7 GiB" memory.required.partial="13.7 GiB" memory.required.kv="5.0 GiB" memory.required.allocations="[13.7 GiB]" memory.weights.total="9.4 GiB" memory.weights.repeating="9.3 GiB" memory.weights.nonrepeating="157.5 MiB" memory.graph.full="3.3 GiB" memory.graph.partial="3.3 GiB"
time=2025-05-08T20:28:27.498+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-08T20:28:27.498+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:28:27.499+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:28:27.499+05:30 level=INFO source=server.go:388 msg="starting llama server" cmd="/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server --model /Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 --ctx-size 32768 --batch-size 512 --embedding --n-gpu-layers 41 --verbose --threads 8 --parallel 4 --port 49948"
time=2025-05-08T20:28:27.499+05:30 level=DEBUG source=server.go:405 msg=subprocess environment="[PATH=/Users/harsh/Desktop/Continue.dev-Granite-manual-test-cases/granite/bin:/Users/harsh/.pyenv/shims:/Users/harsh/.pyenv/bin:/Users/harsh/.pyenv/bin:/opt/homebrew/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/harsh/.local/bin LD_LIBRARY_PATH=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal]"
time=2025-05-08T20:28:27.501+05:30 level=INFO source=sched.go:449 msg="loaded runners" count=2
time=2025-05-08T20:28:27.501+05:30 level=INFO source=server.go:587 msg="waiting for llama runner to start responding"
time=2025-05-08T20:28:27.501+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server error"
INFO [main] starting c++ runner | tid="0x1f53f3240" timestamp=1746716307
INFO [main] build info | build=3871 commit="f37ceeaa" tid="0x1f53f3240" timestamp=1746716307
INFO [main] system info | n_threads=8 n_threads_batch=8 system_info="AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | " tid="0x1f53f3240" timestamp=1746716307 total_threads=10
INFO [main] HTTP server listening | hostname="127.0.0.1" n_threads_http="9" port="49948" tid="0x1f53f3240" timestamp=1746716307
llama_model_loader: loaded meta data with 40 key-value pairs and 362 tensors from /Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = granite
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Granite 3.2 8b Instruct
llama_model_loader: - kv   3:                           general.finetune str              = instruct
llama_model_loader: - kv   4:                           general.basename str              = granite-3.2
llama_model_loader: - kv   5:                         general.size_label str              = 8B
llama_model_loader: - kv   6:                            general.license str              = apache-2.0
llama_model_loader: - kv   7:                   general.base_model.count u32              = 1
llama_model_loader: - kv   8:                  general.base_model.0.name str              = Granite 3.1 8b Instruct
llama_model_loader: - kv   9:          general.base_model.0.organization str              = Ibm Granite
llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/ibm-granite/gr...
llama_model_loader: - kv  11:                               general.tags arr[str,3]       = ["language", "granite-3.2", "text-gen...
llama_model_loader: - kv  12:                        granite.block_count u32              = 40
llama_model_loader: - kv  13:                     granite.context_length u32              = 131072
llama_model_loader: - kv  14:                   granite.embedding_length u32              = 4096
llama_model_loader: - kv  15:                granite.feed_forward_length u32              = 12800
llama_model_loader: - kv  16:               granite.attention.head_count u32              = 32
llama_model_loader: - kv  17:            granite.attention.head_count_kv u32              = 8
llama_model_loader: - kv  18:                     granite.rope.freq_base f32              = 10000000.000000
llama_model_loader: - kv  19:   granite.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  20:                          general.file_type u32              = 15
llama_model_loader: - kv  21:                         granite.vocab_size u32              = 49155
llama_model_loader: - kv  22:               granite.rope.dimension_count u32              = 128
llama_model_loader: - kv  23:                    granite.attention.scale f32              = 0.007812
llama_model_loader: - kv  24:                    granite.embedding_scale f32              = 12.000000
llama_model_loader: - kv  25:                     granite.residual_scale f32              = 0.220000
llama_model_loader: - kv  26:                        granite.logit_scale f32              = 16.000000
llama_model_loader: - kv  27:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  28:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  29:                      tokenizer.ggml.tokens arr[str,49155]   = ["<|end_of_text|>", "<fim_prefix>", "...
llama_model_loader: - kv  30:                  tokenizer.ggml.token_type arr[i32,49155]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  31:                      tokenizer.ggml.merges arr[str,48891]   = ["Ġ Ġ", "ĠĠ ĠĠ", "ĠĠĠĠ ĠĠ...
llama_model_loader: - kv  32:                tokenizer.ggml.bos_token_id u32              = 0
llama_model_loader: - kv  33:                tokenizer.ggml.eos_token_id u32              = 0
llama_model_loader: - kv  34:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 0
llama_model_loader: - kv  36:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  37:                    tokenizer.chat_template str              = {%- if messages[0]['role'] == 'system...
llama_model_loader: - kv  38:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  39:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   81 tensors
llama_model_loader: - type q4_K:  240 tensors
llama_model_loader: - type q6_K:   41 tensors
llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
llm_load_vocab: special tokens cache size = 22
llm_load_vocab: token to piece cache size = 0.2826 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = granite
llm_load_print_meta: vocab type       = BPE
llm_load_print_meta: n_vocab          = 49155
llm_load_print_meta: n_merges         = 48891
llm_load_print_meta: vocab_only       = 0
llm_load_print_meta: n_ctx_train      = 131072
llm_load_print_meta: n_embd           = 4096
llm_load_print_meta: n_layer          = 40
llm_load_print_meta: n_head           = 32
llm_load_print_meta: n_head_kv        = 8
llm_load_print_meta: n_rot            = 128
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_embd_head_k    = 128
llm_load_print_meta: n_embd_head_v    = 128
llm_load_print_meta: n_gqa            = 4
llm_load_print_meta: n_embd_k_gqa     = 1024
llm_load_print_meta: n_embd_v_gqa     = 1024
llm_load_print_meta: f_norm_eps       = 0.0e+00
llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 1.6e+01
llm_load_print_meta: n_ff             = 12800
llm_load_print_meta: n_expert         = 0
llm_load_print_meta: n_expert_used    = 0
llm_load_print_meta: causal attn      = 1
llm_load_print_meta: pooling type     = 0
llm_load_print_meta: rope type        = 0
llm_load_print_meta: rope scaling     = linear
llm_load_print_meta: freq_base_train  = 10000000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: n_ctx_orig_yarn  = 131072
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: ssm_dt_b_c_rms   = 0
llm_load_print_meta: model type       = 3B
llm_load_print_meta: model ftype      = Q4_K - Medium
llm_load_print_meta: model params     = 8.17 B
llm_load_print_meta: model size       = 4.60 GiB (4.84 BPW) 
llm_load_print_meta: general.name     = Granite 3.2 8b Instruct
llm_load_print_meta: BOS token        = 0 '<|end_of_text|>'
llm_load_print_meta: EOS token        = 0 '<|end_of_text|>'
llm_load_print_meta: UNK token        = 0 '<|end_of_text|>'
llm_load_print_meta: PAD token        = 0 '<|end_of_text|>'
llm_load_print_meta: LF token         = 145 'Ä'
llm_load_print_meta: EOG token        = 0 '<|end_of_text|>'
llm_load_print_meta: max token length = 512
llm_load_print_meta: f_embedding_scale = 12.000000
llm_load_print_meta: f_residual_scale  = 0.220000
llm_load_print_meta: f_attention_scale = 0.007812
llm_load_tensors: ggml ctx size =    0.34 MiB
ggml_backend_metal_log_allocated_size: allocated buffer, size =  4712.23 MiB, ( 4712.30 / 21845.34)
llm_load_tensors: offloading 40 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 41/41 layers to GPU
llm_load_tensors:        CPU buffer size =   157.51 MiB
llm_load_tensors:      Metal buffer size =  4712.22 MiB
llama_new_context_with_model: n_ctx      = 32768
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 10000000.0
llama_new_context_with_model: freq_scale = 1
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_init: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)
ggml_metal_init: simdgroup reduction support   = true
ggml_metal_init: simdgroup matrix mul. support = true
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB
time=2025-05-08T20:28:27.753+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server loading model"
time=2025-05-08T20:28:27.753+05:30 level=DEBUG source=server.go:632 msg="model load progress 1.00"
time=2025-05-08T20:28:28.005+05:30 level=DEBUG source=server.go:635 msg="model load completed, waiting for server to become available" status="llm server loading model"
llama_kv_cache_init:      Metal KV buffer size =  5120.00 MiB
llama_new_context_with_model: KV self size  = 5120.00 MiB, K (f16): 2560.00 MiB, V (f16): 2560.00 MiB
llama_new_context_with_model:        CPU  output buffer size =     0.81 MiB
llama_new_context_with_model:      Metal compute buffer size =  2144.00 MiB
llama_new_context_with_model:        CPU compute buffer size =    72.01 MiB
llama_new_context_with_model: graph nodes  = 1368
llama_new_context_with_model: graph splits = 2
DEBUG [initialize] initializing slots | n_slots=4 tid="0x1f53f3240" timestamp=1746716309
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=0 tid="0x1f53f3240" timestamp=1746716309
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=1 tid="0x1f53f3240" timestamp=1746716309
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=2 tid="0x1f53f3240" timestamp=1746716309
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=3 tid="0x1f53f3240" timestamp=1746716309
INFO [main] model loaded | tid="0x1f53f3240" timestamp=1746716309
DEBUG [update_slots] all slots are idle and system prompt is empty, clear the KV cache | tid="0x1f53f3240" timestamp=1746716309
DEBUG [process_single_task] slot data | n_idle_slots=4 n_processing_slots=0 task_id=0 tid="0x1f53f3240" timestamp=1746716309
time=2025-05-08T20:28:29.774+05:30 level=INFO source=server.go:626 msg="llama runner started in 2.27 seconds"
time=2025-05-08T20:28:29.774+05:30 level=DEBUG source=sched.go:462 msg="finished setting up runner" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
DEBUG [process_single_task] slot data | n_idle_slots=4 n_processing_slots=0 task_id=1 tid="0x1f53f3240" timestamp=1746716309
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=49952 status=200 tid="0x16be67000" timestamp=1746716309
time=2025-05-08T20:28:29.784+05:30 level=DEBUG source=routes.go:1422 msg="chat request" images=0 prompt="<|start_of_role|>system<|end_of_role|><important_rules>\n  Always include the language and file name in the info string when you write code blocks. \n  If you are editing \"src/main.py\" for example, your code block should start with '```python src/main.py'\n\n  When addressing code modification requests, present a concise code snippet that\n  emphasizes only the necessary changes and uses abbreviated placeholders for\n  unmodified sections. For instance:\n\n  ```typescript /path/to/file\n  // ... rest of code here ...\n\n  {{ modified code here }}\n\n  // ... rest of code here ...\n\n  {{ another modification }}\n\n  // ... rest of code here ...\n  ```\n\n  Since users have access to their complete file, they prefer reading only the\n  relevant modifications. It's perfectly acceptable to omit unmodified portions\n  at the beginning, middle, or end of files using these \"lazy\" comments. Only\n  provide the complete file when explicitly requested. Include a concise explanation\n  of changes unless the user specifically asks for code only.\n</important_rules><|end_of_text|>\n<|start_of_role|>user<|end_of_role|>hi<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
DEBUG [process_single_task] slot data | n_idle_slots=4 n_processing_slots=0 task_id=2 tid="0x1f53f3240" timestamp=1746716309
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=3 tid="0x1f53f3240" timestamp=1746716309
DEBUG [update_slots] slot progression | ga_i=0 n_past=0 n_past_se=0 n_prompt_tokens_processed=244 slot_id=0 task_id=3 tid="0x1f53f3240" timestamp=1746716309
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=3 tid="0x1f53f3240" timestamp=1746716309
DEBUG [print_timings] prompt eval time     =    1446.65 ms /   244 tokens (    5.93 ms per token,   168.67 tokens per second) | n_prompt_tokens_processed=244 n_tokens_second=168.6653044408745 slot_id=0 t_prompt_processing=1446.652 t_token=5.928901639344263 task_id=3 tid="0x1f53f3240" timestamp=1746716313
DEBUG [print_timings] generation eval time =    1843.63 ms /    41 runs   (   44.97 ms per token,    22.24 tokens per second) | n_decoded=41 n_tokens_second=22.238735538041794 slot_id=0 t_token=44.96658536585366 t_token_generation=1843.63 task_id=3 tid="0x1f53f3240" timestamp=1746716313
DEBUG [print_timings]           total time =    3290.28 ms | slot_id=0 t_prompt_processing=1446.652 t_token_generation=1843.63 t_total=3290.282 task_id=3 tid="0x1f53f3240" timestamp=1746716313
DEBUG [update_slots] slot released | n_cache_tokens=285 n_ctx=32768 n_past=284 n_system_tokens=0 slot_id=0 task_id=3 tid="0x1f53f3240" timestamp=1746716313 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/completion" remote_addr="127.0.0.1" remote_port=49952 status=200 tid="0x16be67000" timestamp=1746716313
[GIN] 2025/05/08 - 20:28:33 | 200 |  5.617399917s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-08T20:28:33.076+05:30 level=DEBUG source=sched.go:466 msg="context for request finished"
time=2025-05-08T20:28:33.076+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 duration=30m0s
time=2025-05-08T20:28:33.076+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 refCount=0
time=2025-05-08T20:28:33.122+05:30 level=DEBUG source=sched.go:575 msg="evaluating already loaded" model=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
DEBUG [process_single_task] slot data | n_idle_slots=4 n_processing_slots=0 task_id=47 tid="0x1f53f3240" timestamp=1746716313
time=2025-05-08T20:28:33.123+05:30 level=DEBUG source=routes.go:1422 msg="chat request" images=0 prompt="<|start_of_role|>system<|end_of_role|>Knowledge Cutoff Date: April 2024.\nYou are Granite, developed by IBM. You are a helpful AI assistant.<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>Given the following... please reply with a title for the chat that is 3-4 words in length, all words used should be directly related to the content of the chat, avoid using verbs unless they are directly related to the content of the chat, no additional text or explanation, you don't need ending punctuation.\n\nHello! How can I assist you today? Let's make sure to follow the guidelines for any code-related requests. If you have a specific file or language in mind, please let me know.<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
DEBUG [process_single_task] slot data | n_idle_slots=4 n_processing_slots=0 task_id=48 tid="0x1f53f3240" timestamp=1746716313
DEBUG [prefix_slot] slot with common prefix found | 0=["slot_id",0,"characters",38]
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=49 tid="0x1f53f3240" timestamp=1746716313
DEBUG [update_slots] slot progression | ga_i=0 n_past=3 n_past_se=0 n_prompt_tokens_processed=149 slot_id=0 task_id=49 tid="0x1f53f3240" timestamp=1746716313
DEBUG [update_slots] kv cache rm [p0, end) | p0=3 slot_id=0 task_id=49 tid="0x1f53f3240" timestamp=1746716313
DEBUG [print_timings] prompt eval time     =     889.67 ms /   149 tokens (    5.97 ms per token,   167.48 tokens per second) | n_prompt_tokens_processed=149 n_tokens_second=167.47858184981777 slot_id=0 t_prompt_processing=889.666 t_token=5.970912751677853 task_id=49 tid="0x1f53f3240" timestamp=1746716314
DEBUG [print_timings] generation eval time =     180.42 ms /     5 runs   (   36.08 ms per token,    27.71 tokens per second) | n_decoded=5 n_tokens_second=27.71342105554878 slot_id=0 t_token=36.083600000000004 t_token_generation=180.418 task_id=49 tid="0x1f53f3240" timestamp=1746716314
DEBUG [print_timings]           total time =    1070.08 ms | slot_id=0 t_prompt_processing=889.666 t_token_generation=180.418 t_total=1070.084 task_id=49 tid="0x1f53f3240" timestamp=1746716314
DEBUG [update_slots] slot released | n_cache_tokens=154 n_ctx=32768 n_past=153 n_system_tokens=0 slot_id=0 task_id=49 tid="0x1f53f3240" timestamp=1746716314 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/completion" remote_addr="127.0.0.1" remote_port=49954 status=200 tid="0x16bef3000" timestamp=1746716314
[GIN] 2025/05/08 - 20:28:34 | 200 |     1.078762s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-08T20:28:34.195+05:30 level=DEBUG source=sched.go:407 msg="context for request finished"
time=2025-05-08T20:28:34.195+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 duration=30m0s
time=2025-05-08T20:28:34.195+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630 refCount=0
[GIN] 2025/05/08 - 20:28:54 | 200 |     106.459µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:28:54 | 200 |      278.25µs |       127.0.0.1 | GET      "/api/ps"
time=2025-05-08T20:29:36.535+05:30 level=DEBUG source=sched.go:341 msg="timer expired, expiring to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:29:36.541+05:30 level=DEBUG source=sched.go:360 msg="runner expired event received" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:29:36.541+05:30 level=DEBUG source=sched.go:375 msg="got lock to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:29:36.541+05:30 level=DEBUG source=server.go:1086 msg="stopping llama server"
time=2025-05-08T20:29:36.541+05:30 level=DEBUG source=server.go:1092 msg="waiting for llama server to exit"
time=2025-05-08T20:29:36.558+05:30 level=DEBUG source=server.go:1096 msg="llama server stopped"
time=2025-05-08T20:29:36.558+05:30 level=DEBUG source=sched.go:380 msg="runner released" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:29:36.558+05:30 level=DEBUG source=sched.go:384 msg="sending an unloaded event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T20:29:36.558+05:30 level=DEBUG source=sched.go:308 msg="ignoring unload event with no pending requests"
[GIN] 2025/05/08 - 20:30:47 | 200 |    4.054667ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/08 - 20:30:47 | 200 |     6.16725ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/08 - 20:30:49 | 200 |   29.378125ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:30:49 | 200 |    27.40725ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:30:49 | 200 |   30.934209ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:30:49 | 200 |   33.201458ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:32:22 | 200 |   29.543334ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:32:22 | 200 |     35.6035ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:32:22 | 200 |    31.37575ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:32:23 | 200 |   47.592667ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:45:24 | 200 |          38µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/08 - 20:45:24 | 200 |      46.834µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/08 - 20:55:17 | 200 |   22.314166ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:55:17 | 200 |   22.880375ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:55:17 | 200 |    23.19825ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/08 - 20:55:17 | 200 |   36.129709ms |       127.0.0.1 | POST     "/api/show"
time=2025-05-08T20:55:20.816+05:30 level=DEBUG source=sched.go:496 msg="gpu reported" gpu=0 library=metal available="21.3 GiB"
time=2025-05-08T20:55:20.817+05:30 level=INFO source=sched.go:507 msg="updated VRAM based on existing loaded models" gpu=0 library=metal total="21.3 GiB" available="7.7 GiB"
time=2025-05-08T20:55:20.817+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[7.7 GiB]"
time=2025-05-08T20:55:20.817+05:30 level=INFO source=sched.go:714 msg="new model will fit in available VRAM in single GPU, loading" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 gpu=0 parallel=1 available=8219755339 required="864.9 MiB"
time=2025-05-08T20:55:20.817+05:30 level=DEBUG source=sched.go:249 msg="new model fits with existing models, loading"
time=2025-05-08T20:55:20.817+05:30 level=INFO source=server.go:105 msg="system memory" total="32.0 GiB" free="13.8 GiB" free_swap="0 B"
time=2025-05-08T20:55:20.817+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[7.7 GiB]"
time=2025-05-08T20:55:20.818+05:30 level=INFO source=memory.go:326 msg="offload to metal" layers.requested=-1 layers.model=13 layers.offload=13 layers.split="" memory.available="[7.7 GiB]" memory.gpu_overhead="0 B" memory.required.full="864.9 MiB" memory.required.partial="864.9 MiB" memory.required.kv="24.0 MiB" memory.required.allocations="[864.9 MiB]" memory.weights.total="240.1 MiB" memory.weights.repeating="195.4 MiB" memory.weights.nonrepeating="44.7 MiB" memory.graph.full="48.0 MiB" memory.graph.partial="48.0 MiB"
time=2025-05-08T20:55:20.818+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-08T20:55:20.818+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:55:20.818+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-08T20:55:20.820+05:30 level=INFO source=server.go:388 msg="starting llama server" cmd="/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server --model /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 --ctx-size 8192 --batch-size 512 --embedding --n-gpu-layers 13 --verbose --threads 8 --parallel 1 --port 51114"
time=2025-05-08T20:55:20.821+05:30 level=DEBUG source=server.go:405 msg=subprocess environment="[PATH=/Users/harsh/Desktop/Continue.dev-Granite-manual-test-cases/granite/bin:/Users/harsh/.pyenv/shims:/Users/harsh/.pyenv/bin:/Users/harsh/.pyenv/bin:/opt/homebrew/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/harsh/.local/bin LD_LIBRARY_PATH=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal]"
time=2025-05-08T20:55:20.822+05:30 level=INFO source=sched.go:449 msg="loaded runners" count=2
time=2025-05-08T20:55:20.822+05:30 level=INFO source=server.go:587 msg="waiting for llama runner to start responding"
time=2025-05-08T20:55:20.823+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server error"
INFO [main] starting c++ runner | tid="0x1f53f3240" timestamp=1746717920
INFO [main] build info | build=3871 commit="f37ceeaa" tid="0x1f53f3240" timestamp=1746717920
INFO [main] system info | n_threads=8 n_threads_batch=8 system_info="AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | " tid="0x1f53f3240" timestamp=1746717920 total_threads=10
INFO [main] HTTP server listening | hostname="127.0.0.1" n_threads_http="9" port="51114" tid="0x1f53f3240" timestamp=1746717920
llama_model_loader: loaded meta data with 24 key-value pairs and 112 tensors from /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = nomic-bert
llama_model_loader: - kv   1:                               general.name str              = nomic-embed-text-v1.5
llama_model_loader: - kv   2:                     nomic-bert.block_count u32              = 12
llama_model_loader: - kv   3:                  nomic-bert.context_length u32              = 2048
llama_model_loader: - kv   4:                nomic-bert.embedding_length u32              = 768
llama_model_loader: - kv   5:             nomic-bert.feed_forward_length u32              = 3072
llama_model_loader: - kv   6:            nomic-bert.attention.head_count u32              = 12
llama_model_loader: - kv   7:    nomic-bert.attention.layer_norm_epsilon f32              = 0.000000
llama_model_loader: - kv   8:                          general.file_type u32              = 1
llama_model_loader: - kv   9:                nomic-bert.attention.causal bool             = false
llama_model_loader: - kv  10:                    nomic-bert.pooling_type u32              = 1
llama_model_loader: - kv  11:                  nomic-bert.rope.freq_base f32              = 1000.000000
llama_model_loader: - kv  12:            tokenizer.ggml.token_type_count u32              = 2
llama_model_loader: - kv  13:                tokenizer.ggml.bos_token_id u32              = 101
llama_model_loader: - kv  14:                tokenizer.ggml.eos_token_id u32              = 102
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = bert
llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,30522]   = ["[PAD]", "[unused0]", "[unused1]", "...
llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 100
llama_model_loader: - kv  20:          tokenizer.ggml.seperator_token_id u32              = 102
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0
llama_model_loader: - kv  22:                tokenizer.ggml.cls_token_id u32              = 101
llama_model_loader: - kv  23:               tokenizer.ggml.mask_token_id u32              = 103
llama_model_loader: - type  f32:   51 tensors
llama_model_loader: - type  f16:   61 tensors
llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
llm_load_vocab: special tokens cache size = 5
llm_load_vocab: token to piece cache size = 0.2032 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = nomic-bert
llm_load_print_meta: vocab type       = WPM
llm_load_print_meta: n_vocab          = 30522
llm_load_print_meta: n_merges         = 0
llm_load_print_meta: vocab_only       = 0
llm_load_print_meta: n_ctx_train      = 2048
llm_load_print_meta: n_embd           = 768
llm_load_print_meta: n_layer          = 12
llm_load_print_meta: n_head           = 12
llm_load_print_meta: n_head_kv        = 12
llm_load_print_meta: n_rot            = 64
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_embd_head_k    = 64
llm_load_print_meta: n_embd_head_v    = 64
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: n_embd_k_gqa     = 768
llm_load_print_meta: n_embd_v_gqa     = 768
llm_load_print_meta: f_norm_eps       = 1.0e-12
llm_load_print_meta: f_norm_rms_eps   = 0.0e+00
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 0.0e+00
llm_load_print_meta: n_ff             = 3072
llm_load_print_meta: n_expert         = 0
llm_load_print_meta: n_expert_used    = 0
llm_load_print_meta: causal attn      = 0
llm_load_print_meta: pooling type     = 1
llm_load_print_meta: rope type        = 2
llm_load_print_meta: rope scaling     = linear
llm_load_print_meta: freq_base_train  = 1000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: n_ctx_orig_yarn  = 2048
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: ssm_dt_b_c_rms   = 0
llm_load_print_meta: model type       = 137M
llm_load_print_meta: model ftype      = F16
llm_load_print_meta: model params     = 136.73 M
llm_load_print_meta: model size       = 260.86 MiB (16.00 BPW) 
llm_load_print_meta: general.name     = nomic-embed-text-v1.5
llm_load_print_meta: BOS token        = 101 '[CLS]'
llm_load_print_meta: EOS token        = 102 '[SEP]'
llm_load_print_meta: UNK token        = 100 '[UNK]'
llm_load_print_meta: SEP token        = 102 '[SEP]'
llm_load_print_meta: PAD token        = 0 '[PAD]'
llm_load_print_meta: CLS token        = 101 '[CLS]'
llm_load_print_meta: MASK token       = 103 '[MASK]'
llm_load_print_meta: LF token         = 0 '[PAD]'
llm_load_print_meta: EOG token        = 102 '[SEP]'
llm_load_print_meta: max token length = 21
llm_load_tensors: ggml ctx size =    0.10 MiB
ggml_backend_metal_log_allocated_size: allocated buffer, size =   260.88 MiB, (  260.94 / 21845.34)
llm_load_tensors: offloading 12 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 13/13 layers to GPU
llm_load_tensors:        CPU buffer size =    44.72 MiB
llm_load_tensors:      Metal buffer size =   260.87 MiB
llama_new_context_with_model: n_ctx      = 8192
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 1000.0
llama_new_context_with_model: freq_scale = 1
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_init: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)
ggml_metal_init: simdgroup reduction support   = true
ggml_metal_init: simdgroup matrix mul. support = true
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB
llama_kv_cache_init:      Metal KV buffer size =   288.00 MiB
llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
llama_new_context_with_model:      Metal compute buffer size =    23.00 MiB
llama_new_context_with_model:        CPU compute buffer size =     3.50 MiB
llama_new_context_with_model: graph nodes  = 453
llama_new_context_with_model: graph splits = 2
time=2025-05-08T20:55:21.074+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server loading model"
time=2025-05-08T20:55:21.074+05:30 level=DEBUG source=server.go:632 msg="model load progress 1.00"
DEBUG [initialize] initializing slots | n_slots=1 tid="0x1f53f3240" timestamp=1746717921
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=0 tid="0x1f53f3240" timestamp=1746717921
INFO [main] model loaded | tid="0x1f53f3240" timestamp=1746717921
DEBUG [update_slots] all slots are idle and system prompt is empty, clear the KV cache | tid="0x1f53f3240" timestamp=1746717921
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=0 tid="0x1f53f3240" timestamp=1746717921
time=2025-05-08T20:55:21.327+05:30 level=INFO source=server.go:626 msg="llama runner started in 0.50 seconds"
time=2025-05-08T20:55:21.327+05:30 level=DEBUG source=sched.go:462 msg="finished setting up runner" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=1 tid="0x1f53f3240" timestamp=1746717921
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=51116 status=200 tid="0x16f567000" timestamp=1746717921
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=2 tid="0x1f53f3240" timestamp=1746717921
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=51117 status=200 tid="0x16f4db000" timestamp=1746717921
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=3 tid="0x1f53f3240" timestamp=1746717921
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=51117 status=200 tid="0x16f4db000" timestamp=1746717921
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=4 tid="0x1f53f3240" timestamp=1746717921
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=5 tid="0x1f53f3240" timestamp=1746717921
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=5 tid="0x1f53f3240" timestamp=1746717921
DEBUG [update_slots] slot released | n_cache_tokens=126 n_ctx=8192 n_past=126 n_system_tokens=0 slot_id=0 task_id=5 tid="0x1f53f3240" timestamp=1746717921 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=51117 status=200 tid="0x16f4db000" timestamp=1746717921
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=8 tid="0x1f53f3240" timestamp=1746717921
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=9 tid="0x1f53f3240" timestamp=1746717921
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=9 tid="0x1f53f3240" timestamp=1746717921
DEBUG [update_slots] slot released | n_cache_tokens=171 n_ctx=8192 n_past=171 n_system_tokens=0 slot_id=0 task_id=9 tid="0x1f53f3240" timestamp=1746717921 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=51118 status=200 tid="0x16f67f000" timestamp=1746717921
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=12 tid="0x1f53f3240" timestamp=1746717921
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=13 tid="0x1f53f3240" timestamp=1746717921
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=13 tid="0x1f53f3240" timestamp=1746717921
DEBUG [update_slots] slot released | n_cache_tokens=331 n_ctx=8192 n_past=331 n_system_tokens=0 slot_id=0 task_id=13 tid="0x1f53f3240" timestamp=1746717921 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=51118 status=200 tid="0x16f67f000" timestamp=1746717921
[GIN] 2025/05/08 - 20:55:21 | 200 |  695.916042ms |       127.0.0.1 | POST     "/api/embed"
time=2025-05-08T20:55:21.480+05:30 level=DEBUG source=sched.go:466 msg="context for request finished"
time=2025-05-08T20:55:21.480+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 duration=5m0s
time=2025-05-08T20:55:21.480+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 refCount=0
time=2025-05-08T20:58:34.196+05:30 level=DEBUG source=sched.go:341 msg="timer expired, expiring to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:58:34.197+05:30 level=DEBUG source=sched.go:360 msg="runner expired event received" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:58:34.197+05:30 level=DEBUG source=sched.go:375 msg="got lock to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:58:34.197+05:30 level=DEBUG source=server.go:1086 msg="stopping llama server"
time=2025-05-08T20:58:34.197+05:30 level=DEBUG source=server.go:1092 msg="waiting for llama server to exit"
time=2025-05-08T20:58:34.230+05:30 level=DEBUG source=server.go:1096 msg="llama server stopped"
time=2025-05-08T20:58:34.230+05:30 level=DEBUG source=sched.go:380 msg="runner released" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:58:34.231+05:30 level=DEBUG source=sched.go:384 msg="sending an unloaded event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-59c55d0e7b6a16d103f324fe4d2cc83843936e1ac65e93b632b6dc577d732630
time=2025-05-08T20:58:34.231+05:30 level=DEBUG source=sched.go:308 msg="ignoring unload event with no pending requests"
time=2025-05-08T21:00:21.482+05:30 level=DEBUG source=sched.go:341 msg="timer expired, expiring to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T21:00:21.485+05:30 level=DEBUG source=sched.go:360 msg="runner expired event received" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T21:00:21.485+05:30 level=DEBUG source=sched.go:375 msg="got lock to unload" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T21:00:21.485+05:30 level=DEBUG source=server.go:1086 msg="stopping llama server"
time=2025-05-08T21:00:21.486+05:30 level=DEBUG source=server.go:1092 msg="waiting for llama server to exit"
time=2025-05-08T21:00:21.523+05:30 level=DEBUG source=server.go:1096 msg="llama server stopped"
time=2025-05-08T21:00:21.523+05:30 level=DEBUG source=sched.go:380 msg="runner released" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T21:00:21.523+05:30 level=DEBUG source=sched.go:384 msg="sending an unloaded event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-08T21:00:21.523+05:30 level=DEBUG source=sched.go:308 msg="ignoring unload event with no pending requests"
[GIN] 2025/05/13 - 19:58:02 | 200 |      51.583µs |       127.0.0.1 | HEAD     "/"
time=2025-05-13T19:58:04.171+05:30 level=INFO source=download.go:175 msg="downloading 6a0746a1ec1a in 16 291 MB part(s)"
time=2025-05-13T19:58:49.482+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 1 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T19:59:14.461+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 7 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T19:59:14.465+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 13 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T19:59:14.466+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 0 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T19:59:14.504+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 10 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T19:59:14.817+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 15 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T19:59:14.844+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 3 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T19:59:16.963+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 11 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T19:59:18.483+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 4 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T19:59:18.483+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 8 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T19:59:19.846+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 3 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:34.838+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 14 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:34.842+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 9 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:35.347+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 6 attempt 0 failed: read tcp [2401:4900:8fdf:bae8:3d36:452c:6e:55b2]:58429->[2606:4700:7::12e]:443: read: connection reset by peer, retrying in 1s"
time=2025-05-13T20:03:35.999+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 9 attempt 0 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": tls: received record with version b325 when expecting version 303, retrying in 1s"
time=2025-05-13T20:03:36.000+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 14 attempt 0 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": tls: received record with version f58b when expecting version 303, retrying in 1s"
time=2025-05-13T20:03:37.496+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 6 attempt 1 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": tls: received record with version 829e when expecting version 303, retrying in 2s"
time=2025-05-13T20:03:37.542+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 9 attempt 1 failed: tls: received record with version e8ee when expecting version 303, retrying in 2s"
time=2025-05-13T20:03:37.543+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 14 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:03:39.201+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 3 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.321+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 11 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.820+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 7 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.822+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 0 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.823+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 13 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.838+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 12 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.838+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 5 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.838+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 2 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.841+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 4 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.853+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 8 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.853+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 1 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:39.862+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 10 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:40.186+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 15 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:45.848+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 12 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:49.233+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 3 attempt 1 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": net/http: TLS handshake timeout, retrying in 2s"
time=2025-05-13T20:03:53.627+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 1 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T20:03:53.629+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 12 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T20:03:53.630+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 10 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:03:53.673+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 3 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:03:53.860+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 15 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:03:53.903+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 0 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:03:53.903+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 9 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:03:53.963+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 14 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:03:53.963+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 4 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T20:03:53.963+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 2 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T20:03:53.963+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 5 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T20:03:53.964+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 11 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:03:53.964+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 6 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:03:53.964+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 8 attempt 0 failed: local error: tls: bad record MAC, retrying in 1s"
time=2025-05-13T20:03:53.964+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 13 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:03:54.015+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 7 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:03:56.969+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 13 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:58.632+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 12 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:58.632+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 1 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:58.678+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 3 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:03:58.966+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 14 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:04:44.884+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 15 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:04:44.972+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 13 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:04:44.990+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 3 attempt 3 failed: local error: tls: bad record MAC, retrying in 8s"
time=2025-05-13T20:04:44.991+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 8 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:04:45.002+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 12 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:04:45.016+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 0 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:04:45.057+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 7 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:04:45.223+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 4 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:04:45.231+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 11 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:04:45.231+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 5 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:04:45.237+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 10 attempt 2 failed: local error: tls: bad record MAC, retrying in 4s"
time=2025-05-13T20:04:45.375+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 6 attempt 3 failed: local error: tls: bad record MAC, retrying in 8s"
time=2025-05-13T20:04:45.375+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 2 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:04:45.375+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 1 attempt 1 failed: local error: tls: bad record MAC, retrying in 2s"
time=2025-05-13T20:04:50.238+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 10 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:39.220+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 9 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:39.993+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 9 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:40.301+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 3 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:40.686+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 6 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:43.280+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 13 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:43.284+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 13 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:43.325+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 0 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:43.330+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 0 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:43.548+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 10 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:43.551+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 10 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:43.686+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 1 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:43.688+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 2 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:43.689+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 1 attempt 2 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 4s"
time=2025-05-13T20:09:43.689+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 2 attempt 2 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 4s"
time=2025-05-13T20:09:44.195+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 15 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.196+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 15 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:44.278+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 14 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.280+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 14 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:44.301+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 8 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.304+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 8 attempt 2 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 4s"
time=2025-05-13T20:09:44.312+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 12 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.314+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 12 attempt 2 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 4s"
time=2025-05-13T20:09:44.366+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 7 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.369+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 7 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:44.532+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 4 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.535+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 4 attempt 2 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 4s"
time=2025-05-13T20:09:44.541+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 11 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.541+05:30 level=INFO source=download.go:370 msg="6a0746a1ec1a part 5 stalled; retrying. If this persists, press ctrl-c to exit, then 'ollama pull' to find a faster connection."
time=2025-05-13T20:09:44.544+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 5 attempt 2 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 4s"
time=2025-05-13T20:09:44.544+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 11 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:47.692+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 1 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:47.692+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 2 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:47.997+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 9 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:48.308+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 8 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:48.318+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 12 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:48.539+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 4 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:48.547+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 5 attempt 3 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 8s"
time=2025-05-13T20:09:51.288+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 13 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:51.334+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 0 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:51.555+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 10 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:52.199+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 15 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:52.286+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 14 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:52.373+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 7 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:52.548+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 11 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:55.697+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 2 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:55.697+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 1 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:56.305+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 3 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T20:09:56.311+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 8 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:56.321+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 12 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:56.542+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 4 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:56.549+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 5 attempt 4 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 16s"
time=2025-05-13T20:09:56.689+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 6 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T20:10:04.002+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 9 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:52.997+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 13 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:53.042+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 0 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:53.262+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 10 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:53.911+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 15 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:53.995+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 14 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:54.083+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 7 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:54.256+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 11 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:57.406+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 2 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:57.406+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 1 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:58.021+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 8 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:58.028+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 12 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:58.251+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 4 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
time=2025-05-13T21:46:58.255+05:30 level=INFO source=download.go:291 msg="6a0746a1ec1a part 5 attempt 5 failed: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/6a/6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250513%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250513T142804Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d40762e2be45e61b02b68056513819b8d7cc593c92d980bd5192547c235a3de0\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host, retrying in 32s"
[GIN] 2025/05/13 - 23:31:30 | 200 |    45.02875ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/13 - 23:31:30 | 200 |   51.344208ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/13 - 23:31:30 | 200 |   64.497625ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/05/13 - 23:31:30 | 200 |   83.293125ms |       127.0.0.1 | POST     "/api/show"
time=2025-05-13T23:31:34.567+05:30 level=DEBUG source=sched.go:224 msg="loading first model" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
time=2025-05-13T23:31:34.567+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-13T23:31:34.567+05:30 level=INFO source=sched.go:714 msg="new model will fit in available VRAM in single GPU, loading" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 gpu=0 parallel=1 available=22906503168 required="864.9 MiB"
time=2025-05-13T23:31:34.568+05:30 level=INFO source=server.go:105 msg="system memory" total="32.0 GiB" free="9.7 GiB" free_swap="0 B"
time=2025-05-13T23:31:34.568+05:30 level=DEBUG source=memory.go:103 msg=evaluating library=metal gpu_count=1 available="[21.3 GiB]"
time=2025-05-13T23:31:34.568+05:30 level=INFO source=memory.go:326 msg="offload to metal" layers.requested=-1 layers.model=13 layers.offload=13 layers.split="" memory.available="[21.3 GiB]" memory.gpu_overhead="0 B" memory.required.full="864.9 MiB" memory.required.partial="864.9 MiB" memory.required.kv="24.0 MiB" memory.required.allocations="[864.9 MiB]" memory.weights.total="240.1 MiB" memory.weights.repeating="195.4 MiB" memory.weights.nonrepeating="44.7 MiB" memory.graph.full="48.0 MiB" memory.graph.partial="48.0 MiB"
time=2025-05-13T23:31:34.568+05:30 level=DEBUG source=common.go:168 msg=extracting runner=metal payload=darwin/arm64/metal/ollama_llama_server.gz
time=2025-05-13T23:31:34.568+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-13T23:31:34.568+05:30 level=DEBUG source=common.go:294 msg="availableServers : found" file=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server
time=2025-05-13T23:31:34.569+05:30 level=INFO source=server.go:388 msg="starting llama server" cmd="/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal/ollama_llama_server --model /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 --ctx-size 8192 --batch-size 512 --embedding --n-gpu-layers 13 --verbose --threads 8 --parallel 1 --port 59585"
time=2025-05-13T23:31:34.569+05:30 level=DEBUG source=server.go:405 msg=subprocess environment="[PATH=/Users/harsh/Desktop/Continue.dev-Granite-manual-test-cases/granite/bin:/Users/harsh/.pyenv/shims:/Users/harsh/.pyenv/bin:/Users/harsh/.pyenv/bin:/opt/homebrew/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/harsh/.local/bin LD_LIBRARY_PATH=/var/folders/h5/6m1jwfrs0d907pzdgx0mp5f40000gn/T/ollama716906519/runners/metal]"
time=2025-05-13T23:31:34.571+05:30 level=INFO source=sched.go:449 msg="loaded runners" count=1
time=2025-05-13T23:31:34.572+05:30 level=INFO source=server.go:587 msg="waiting for llama runner to start responding"
time=2025-05-13T23:31:34.572+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server error"
INFO [main] starting c++ runner | tid="0x1f53f3240" timestamp=1747159294
INFO [main] build info | build=3871 commit="f37ceeaa" tid="0x1f53f3240" timestamp=1747159294
INFO [main] system info | n_threads=8 n_threads_batch=8 system_info="AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | " tid="0x1f53f3240" timestamp=1747159294 total_threads=10
INFO [main] HTTP server listening | hostname="127.0.0.1" n_threads_http="9" port="59585" tid="0x1f53f3240" timestamp=1747159294
llama_model_loader: loaded meta data with 24 key-value pairs and 112 tensors from /Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = nomic-bert
llama_model_loader: - kv   1:                               general.name str              = nomic-embed-text-v1.5
llama_model_loader: - kv   2:                     nomic-bert.block_count u32              = 12
llama_model_loader: - kv   3:                  nomic-bert.context_length u32              = 2048
llama_model_loader: - kv   4:                nomic-bert.embedding_length u32              = 768
llama_model_loader: - kv   5:             nomic-bert.feed_forward_length u32              = 3072
llama_model_loader: - kv   6:            nomic-bert.attention.head_count u32              = 12
llama_model_loader: - kv   7:    nomic-bert.attention.layer_norm_epsilon f32              = 0.000000
llama_model_loader: - kv   8:                          general.file_type u32              = 1
llama_model_loader: - kv   9:                nomic-bert.attention.causal bool             = false
llama_model_loader: - kv  10:                    nomic-bert.pooling_type u32              = 1
llama_model_loader: - kv  11:                  nomic-bert.rope.freq_base f32              = 1000.000000
llama_model_loader: - kv  12:            tokenizer.ggml.token_type_count u32              = 2
llama_model_loader: - kv  13:                tokenizer.ggml.bos_token_id u32              = 101
llama_model_loader: - kv  14:                tokenizer.ggml.eos_token_id u32              = 102
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = bert
llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,30522]   = ["[PAD]", "[unused0]", "[unused1]", "...
llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 100
llama_model_loader: - kv  20:          tokenizer.ggml.seperator_token_id u32              = 102
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0
llama_model_loader: - kv  22:                tokenizer.ggml.cls_token_id u32              = 101
llama_model_loader: - kv  23:               tokenizer.ggml.mask_token_id u32              = 103
llama_model_loader: - type  f32:   51 tensors
llama_model_loader: - type  f16:   61 tensors
llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
llm_load_vocab: special tokens cache size = 5
llm_load_vocab: token to piece cache size = 0.2032 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = nomic-bert
llm_load_print_meta: vocab type       = WPM
llm_load_print_meta: n_vocab          = 30522
llm_load_print_meta: n_merges         = 0
llm_load_print_meta: vocab_only       = 0
llm_load_print_meta: n_ctx_train      = 2048
llm_load_print_meta: n_embd           = 768
llm_load_print_meta: n_layer          = 12
llm_load_print_meta: n_head           = 12
llm_load_print_meta: n_head_kv        = 12
llm_load_print_meta: n_rot            = 64
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_embd_head_k    = 64
llm_load_print_meta: n_embd_head_v    = 64
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: n_embd_k_gqa     = 768
llm_load_print_meta: n_embd_v_gqa     = 768
llm_load_print_meta: f_norm_eps       = 1.0e-12
llm_load_print_meta: f_norm_rms_eps   = 0.0e+00
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 0.0e+00
llm_load_print_meta: n_ff             = 3072
llm_load_print_meta: n_expert         = 0
llm_load_print_meta: n_expert_used    = 0
llm_load_print_meta: causal attn      = 0
llm_load_print_meta: pooling type     = 1
llm_load_print_meta: rope type        = 2
llm_load_print_meta: rope scaling     = linear
llm_load_print_meta: freq_base_train  = 1000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: n_ctx_orig_yarn  = 2048
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: ssm_dt_b_c_rms   = 0
llm_load_print_meta: model type       = 137M
llm_load_print_meta: model ftype      = F16
llm_load_print_meta: model params     = 136.73 M
llm_load_print_meta: model size       = 260.86 MiB (16.00 BPW) 
llm_load_print_meta: general.name     = nomic-embed-text-v1.5
llm_load_print_meta: BOS token        = 101 '[CLS]'
llm_load_print_meta: EOS token        = 102 '[SEP]'
llm_load_print_meta: UNK token        = 100 '[UNK]'
llm_load_print_meta: SEP token        = 102 '[SEP]'
llm_load_print_meta: PAD token        = 0 '[PAD]'
llm_load_print_meta: CLS token        = 101 '[CLS]'
llm_load_print_meta: MASK token       = 103 '[MASK]'
llm_load_print_meta: LF token         = 0 '[PAD]'
llm_load_print_meta: EOG token        = 102 '[SEP]'
llm_load_print_meta: max token length = 21
llm_load_tensors: ggml ctx size =    0.10 MiB
ggml_backend_metal_log_allocated_size: allocated buffer, size =   260.88 MiB, (  260.94 / 21845.34)
llm_load_tensors: offloading 12 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 13/13 layers to GPU
llm_load_tensors:        CPU buffer size =    44.72 MiB
llm_load_tensors:      Metal buffer size =   260.87 MiB
llama_new_context_with_model: n_ctx      = 8192
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 1000.0
llama_new_context_with_model: freq_scale = 1
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_init: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)
ggml_metal_init: simdgroup reduction support   = true
ggml_metal_init: simdgroup matrix mul. support = true
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB
time=2025-05-13T23:31:34.823+05:30 level=INFO source=server.go:621 msg="waiting for server to become available" status="llm server loading model"
time=2025-05-13T23:31:34.824+05:30 level=DEBUG source=server.go:632 msg="model load progress 1.00"
llama_kv_cache_init:      Metal KV buffer size =   288.00 MiB
llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
llama_new_context_with_model:      Metal compute buffer size =    23.00 MiB
llama_new_context_with_model:        CPU compute buffer size =     3.50 MiB
llama_new_context_with_model: graph nodes  = 453
llama_new_context_with_model: graph splits = 2
DEBUG [initialize] initializing slots | n_slots=1 tid="0x1f53f3240" timestamp=1747159295
DEBUG [initialize] new slot | n_ctx_slot=8192 slot_id=0 tid="0x1f53f3240" timestamp=1747159295
INFO [main] model loaded | tid="0x1f53f3240" timestamp=1747159295
DEBUG [update_slots] all slots are idle and system prompt is empty, clear the KV cache | tid="0x1f53f3240" timestamp=1747159295
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=0 tid="0x1f53f3240" timestamp=1747159295
time=2025-05-13T23:31:35.076+05:30 level=INFO source=server.go:626 msg="llama runner started in 0.50 seconds"
time=2025-05-13T23:31:35.076+05:30 level=DEBUG source=sched.go:462 msg="finished setting up runner" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=1 tid="0x1f53f3240" timestamp=1747159295
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59587 status=200 tid="0x16f517000" timestamp=1747159295
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=2 tid="0x1f53f3240" timestamp=1747159295
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59588 status=200 tid="0x16f62f000" timestamp=1747159295
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=3 tid="0x1f53f3240" timestamp=1747159295
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59588 status=200 tid="0x16f62f000" timestamp=1747159295
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=4 tid="0x1f53f3240" timestamp=1747159295
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=5 tid="0x1f53f3240" timestamp=1747159295
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=5 tid="0x1f53f3240" timestamp=1747159295
DEBUG [update_slots] slot released | n_cache_tokens=171 n_ctx=8192 n_past=171 n_system_tokens=0 slot_id=0 task_id=5 tid="0x1f53f3240" timestamp=1747159295 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59588 status=200 tid="0x16f62f000" timestamp=1747159295
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=8 tid="0x1f53f3240" timestamp=1747159295
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=9 tid="0x1f53f3240" timestamp=1747159295
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=9 tid="0x1f53f3240" timestamp=1747159295
DEBUG [update_slots] slot released | n_cache_tokens=126 n_ctx=8192 n_past=126 n_system_tokens=0 slot_id=0 task_id=9 tid="0x1f53f3240" timestamp=1747159295 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59589 status=200 tid="0x16f6bb000" timestamp=1747159295
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=12 tid="0x1f53f3240" timestamp=1747159295
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=13 tid="0x1f53f3240" timestamp=1747159295
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=13 tid="0x1f53f3240" timestamp=1747159295
DEBUG [update_slots] slot released | n_cache_tokens=331 n_ctx=8192 n_past=331 n_system_tokens=0 slot_id=0 task_id=13 tid="0x1f53f3240" timestamp=1747159295 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59589 status=200 tid="0x16f6bb000" timestamp=1747159295
[GIN] 2025/05/13 - 23:31:35 | 200 |  677.090333ms |       127.0.0.1 | POST     "/api/embed"
time=2025-05-13T23:31:35.221+05:30 level=DEBUG source=sched.go:466 msg="context for request finished"
time=2025-05-13T23:31:35.221+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 duration=5m0s
time=2025-05-13T23:31:35.222+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 refCount=0
time=2025-05-13T23:31:41.686+05:30 level=DEBUG source=sched.go:575 msg="evaluating already loaded" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=16 tid="0x1f53f3240" timestamp=1747159301
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=17 tid="0x1f53f3240" timestamp=1747159301
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59593 status=200 tid="0x16f747000" timestamp=1747159301
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=18 tid="0x1f53f3240" timestamp=1747159301
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=19 tid="0x1f53f3240" timestamp=1747159301
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=19 tid="0x1f53f3240" timestamp=1747159301
time=2025-05-13T23:31:41.713+05:30 level=DEBUG source=sched.go:407 msg="context for request finished"
time=2025-05-13T23:31:41.713+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 duration=5m0s
time=2025-05-13T23:31:41.713+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 refCount=0
time=2025-05-13T23:31:41.713+05:30 level=ERROR source=routes.go:422 msg="embedding generation failed" error="do embedding request: Post \"http://127.0.0.1:59585/embedding\": context canceled"
[GIN] 2025/05/13 - 23:31:41 | 500 |   36.952625ms |       127.0.0.1 | POST     "/api/embed"
DEBUG [update_slots] slot released | n_cache_tokens=53 n_ctx=8192 n_past=53 n_system_tokens=0 slot_id=0 task_id=19 tid="0x1f53f3240" timestamp=1747159301 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59593 status=200 tid="0x16f747000" timestamp=1747159301
time=2025-05-13T23:34:55.711+05:30 level=DEBUG source=sched.go:575 msg="evaluating already loaded" model=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=22 tid="0x1f53f3240" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=23 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59608 status=200 tid="0x16f7d3000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=24 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59608 status=200 tid="0x16f7d3000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=25 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59609 status=200 tid="0x16f85f000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=26 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59609 status=200 tid="0x16f85f000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=27 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59610 status=200 tid="0x16f5a3000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=28 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59610 status=200 tid="0x16f5a3000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=29 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59610 status=200 tid="0x16f5a3000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=30 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59611 status=200 tid="0x16f8eb000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=31 tid="0x1f53f3240" timestamp=1747159495
DEBUG [log_server_request] request | method="POST" params={} path="/tokenize" remote_addr="127.0.0.1" remote_port=59611 status=200 tid="0x16f8eb000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=32 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=33 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=33 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=180 n_ctx=8192 n_past=180 n_system_tokens=0 slot_id=0 task_id=33 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59612 status=200 tid="0x16f977000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=36 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=37 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=37 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=115 n_ctx=8192 n_past=115 n_system_tokens=0 slot_id=0 task_id=37 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59612 status=200 tid="0x16f977000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=40 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=41 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=41 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=156 n_ctx=8192 n_past=156 n_system_tokens=0 slot_id=0 task_id=41 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59612 status=200 tid="0x16f977000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=44 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=45 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=45 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=83 n_ctx=8192 n_past=83 n_system_tokens=0 slot_id=0 task_id=45 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59613 status=200 tid="0x16f517000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=48 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=49 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=49 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=279 n_ctx=8192 n_past=279 n_system_tokens=0 slot_id=0 task_id=49 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59613 status=200 tid="0x16f517000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=52 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=53 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=53 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=55 n_ctx=8192 n_past=55 n_system_tokens=0 slot_id=0 task_id=53 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59614 status=200 tid="0x16f62f000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=56 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=57 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=57 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=140 n_ctx=8192 n_past=140 n_system_tokens=0 slot_id=0 task_id=57 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59614 status=200 tid="0x16f62f000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=60 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=61 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=61 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=60 n_ctx=8192 n_past=60 n_system_tokens=0 slot_id=0 task_id=61 tid="0x1f53f3240" timestamp=1747159495 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59614 status=200 tid="0x16f62f000" timestamp=1747159495
DEBUG [process_single_task] slot data | n_idle_slots=1 n_processing_slots=0 task_id=64 tid="0x1f53f3240" timestamp=1747159495
DEBUG [launch_slot_with_data] slot is processing task | slot_id=0 task_id=65 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] kv cache rm [p0, end) | p0=0 slot_id=0 task_id=65 tid="0x1f53f3240" timestamp=1747159495
DEBUG [update_slots] slot released | n_cache_tokens=69 n_ctx=8192 n_past=69 n_system_tokens=0 slot_id=0 task_id=65 tid="0x1f53f3240" timestamp=1747159496 truncated=false
DEBUG [log_server_request] request | method="POST" params={} path="/embedding" remote_addr="127.0.0.1" remote_port=59615 status=200 tid="0x16f6bb000" timestamp=1747159496
[GIN] 2025/05/13 - 23:34:56 | 200 |  300.547041ms |       127.0.0.1 | POST     "/api/embed"
time=2025-05-13T23:34:56.013+05:30 level=DEBUG source=sched.go:407 msg="context for request finished"
time=2025-05-13T23:34:56.014+05:30 level=DEBUG source=sched.go:339 msg="runner with non-zero duration has gone idle, adding timer" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 duration=5m0s
time=2025-05-13T23:34:56.014+05:30 level=DEBUG source=sched.go:357 msg="after processing request finished event" modelPath=/Users/harsh/.ollama/models/blobs/sha256-970aa74c0a90ef7482477cf803618e776e173c007bf957f635f1015bfcfef0e6 refCount=0
